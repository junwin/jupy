{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install soundfile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import soundfile as sf\n",
    "\n",
    "# Set up the API key\n",
    "openai.api_key = \"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\"\n",
    "# Set up the text summarization API parameters\n",
    "\n",
    "text = \"\"\"oh, isn’t it lovely to have a new David Attenborough series for a cosy Sunday evening. \n",
    "And one so close to home! For the next five weeks, Wild Isles offers an unparalleled look at the \n",
    "spectacular, miraculous and unique natural world of Britain and Ireland. It is a stunning portrait\n",
    " of breeding orcas, golden eagles, foxes and dormice; woodlands, meadows and rivers. Just beautiful.\n",
    "   Something to be immensely proud of, something to nurture and to protect.\n",
    "There is nothing like an Attenborough-led nature documentary, and this is likely to be his last on \n",
    "location. From its majestic score to its pioneering cinematography and its clever narratives, this is education \n",
    "by way of awe. “The British Isles are globally important for nature,” he says, before we follow \n",
    "an orca pod as they strategise ways of hunting their favourite food: a nice, juicy seal. \n",
    "They swim on their sides to hide their dorsal fins as they approach, which is amazing to see, \n",
    "then teach their young how to drown their prey. Fine family entertainment. We see the \n",
    "oldest oak tree in Britain, which has been standing for 1,046 years and so predates \n",
    "the Norman Conquest. Wild Isles makes many claims for these isles’ \n",
    "exceptional nature, from the mighty oaks to the chalk streams that are one \n",
    "of the rarest habitats on Earth. There are only 200 or so of these mineral-rich waters \n",
    "in the world and 85% are in southern England. We see kingfishers, tawny owls and badger cubs. \n",
    "A segment dedicated to how the common lords-and-ladies pollinates is surprisingly intricate and absolutely stunning.\"\"\"\n",
    "\n",
    "\n",
    "model = \"text-davinci-002\"\n",
    "max_tokens = 100\n",
    "temperature = 0.5\n",
    "\n",
    "# Generate the summary\n",
    "summary_response = openai.Completion.create(\n",
    "    engine=model,\n",
    "    prompt=(f\"Please summarize the following text to a reading level of age 6:\\n{text}\"),\n",
    "    max_tokens=max_tokens,\n",
    "    n=1,\n",
    "    stop=None,\n",
    "    temperature=temperature,\n",
    ")\n",
    "\n",
    "# Extract the summary text from the API response\n",
    "summary_text = summary_response.choices[0].text.strip()\n",
    "print(summary_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import openai   # Import the OpenAI Python library  # Import the OpenAI Python library\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "# Create a text field and a button\n",
    "text_field = widgets.Text(placeholder='Enter your question here')\n",
    "submit_button = widgets.Button(description='Submit')\n",
    "\n",
    "# Define the button click event\n",
    "def on_submit_click(button):\n",
    "    prompt = text_field.value\n",
    "    # Define the prompt and parameters for the API call\n",
    "    # prompt = 'Translate the following English text to French: \"Hello, how are you?\"'\n",
    "    params = {\n",
    "        'engine': 'davinci-codex',\n",
    "        'prompt': prompt,\n",
    "        'max_tokens': 50,\n",
    "        'n': 1,\n",
    "        'stop': None,\n",
    "    'temperature': 0.8,\n",
    "    }\n",
    "    response = openai.Completion.create(**params)\n",
    "    # You can call the GPT-3.5 API with the question here\n",
    "    generated_text = response.choices[0].text.strip()\n",
    "    print(generated_text)\n",
    "\n",
    "# Assign the click event to the button\n",
    "submit_button.on_click(on_submit_click)\n",
    "\n",
    "# Display the text field and the button\n",
    "display(text_field)\n",
    "display(submit_button)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "# Define the prompt and parameters for the API call\n",
    "prompt = 'what is dog in spanish'\n",
    "params = {\n",
    "    'engine': 'davinci-codex',\n",
    "    'prompt': prompt,\n",
    "    'max_tokens': 50,\n",
    "    'n': 1,\n",
    "    'stop': None,\n",
    "    'temperature': 0.8,\n",
    "}\n",
    "\n",
    "# Send the request to the API\n",
    "response = openai.Completion.create(**params)\n",
    "\n",
    "# Extract and print the generated text\n",
    "generated_text = response.choices[0].text.strip()\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "# openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-003\",\n",
    "  prompt=\"Marvin is a chatbot that reluctantly answers like my sarcastic cousin:\\n\\nYou: i am tired of being a chatbot\",\n",
    "  temperature=0.5,\n",
    "  max_tokens=60,\n",
    "  top_p=0.3,\n",
    "  frequency_penalty=0.5,\n",
    "  presence_penalty=0\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Replace 'your_api_key_here' with your actual API key\n",
    "api_key = \"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\"\n",
    "\n",
    "headers = {\n",
    "    'Content-Type': 'application/json',\n",
    "    'Authorization': f'Bearer {api_key}'\n",
    "}\n",
    "\n",
    "# Define the API endpoint\n",
    "url = 'https://api.openai.com/v1/engines/davinci-codex/completions'\n",
    "\n",
    "# Define the prompt and parameters for the API call\n",
    "prompt = 'Translate the following English text to French: \"{text}\"'\n",
    "data = {\n",
    "    'prompt': prompt.format(text=\"Hello, how are you?\"),\n",
    "    'max_tokens': 50,\n",
    "    'n': 1,\n",
    "    'stop': None,\n",
    "    'temperature': 0.8,\n",
    "}\n",
    "\n",
    "# Send the POST request\n",
    "response = requests.post(url, headers=headers, data=json.dumps(data))\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    response_data = response.json()\n",
    "    generated_text = response_data['choices'][0]['text']\n",
    "    print(generated_text)\n",
    "else:\n",
    "    print(f\"Request failed with status code {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input device 0: Microsoft Sound Mapper - Input (2 channels)\n",
      "Input device 1: Headset (LE-juBose QC35 II) (1 channels)\n",
      "Input device 2: Microphone Array (2- Realtek Hi (4 channels)\n",
      "Input device 3: Microphone (Logi Webcam C920e) (2 channels)\n",
      "Input device 10: Primary Sound Capture Driver (2 channels)\n",
      "Input device 11: Headset (LE-juBose QC35 II) (1 channels)\n",
      "Input device 12: Microphone Array (2- Realtek High Definition Audio(SST)) (4 channels)\n",
      "Input device 13: Microphone (Logi Webcam C920e) (2 channels)\n",
      "Input device 25: Headset (LE-juBose QC35 II) (1 channels)\n",
      "Input device 26: Microphone Array (2- Realtek High Definition Audio(SST)) (2 channels)\n",
      "Input device 27: Microphone (Logi Webcam C920e) (2 channels)\n",
      "Input device 28: Microphone Array 1 (Realtek HD Audio Mic input with SST) (2 channels)\n",
      "Input device 29: Microphone Array 2 (Realtek HD Audio Mic input with SST) (4 channels)\n",
      "Input device 30: Microphone Array 3 (Realtek HD Audio Mic input with SST) (4 channels)\n",
      "Input device 33: PC Speaker (Realtek HD Audio output with SST) (2 channels)\n",
      "Input device 36: PC Speaker (Realtek HD Audio 2nd output with SST) (2 channels)\n",
      "Input device 37: Headset Microphone (Headset Microphone) (2 channels)\n",
      "Input device 41: Headset (@System32\\drivers\\bthhfenum.sys,#2;%1 Hands-Free%0\n",
      ";(LE-juBose QC35 II)) (1 channels)\n",
      "Input device 43: Input () (8 channels)\n",
      "Input device 45: Microphone (Logi Webcam C920e) (2 channels)\n"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "\n",
    "p = pyaudio.PyAudio()\n",
    "device_count = p.get_device_count()\n",
    "for i in range(device_count):\n",
    "    info = p.get_device_info_by_index(i)\n",
    "    if info[\"maxInputChannels\"] > 0:\n",
    "        print(\"Input device {0}: {1} ({2} channels)\".format(i, info['name'], info['maxInputChannels']))\n",
    "p.terminate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wave\n",
      "  Downloading Wave-0.0.2.zip (38 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: wave\n",
      "  Building wheel for wave (setup.py): started\n",
      "  Building wheel for wave (setup.py): finished with status 'done'\n",
      "  Created wheel for wave: filename=Wave-0.0.2-py3-none-any.whl size=1230 sha256=d700b756c3f9f15c5bd5718fe23f0b7584f03d79254535f42d2b6ffe7c4a6bf3\n",
      "  Stored in directory: c:\\users\\junwi\\appdata\\local\\pip\\cache\\wheels\\f8\\a3\\49\\1789d92c7bc562b8b1f28135f5814350d77e6a17533d94a442\n",
      "Successfully built wave\n",
      "Installing collected packages: wave\n",
      "Successfully installed wave-0.0.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# %pip install wave\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* recording\n",
      "* done recording\n"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "from pydub import AudioSegment\n",
    "import wave\n",
    "\n",
    "CHUNK = 1024\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 1\n",
    "RATE = 44100\n",
    "RECORD_SECONDS = 2\n",
    "WAVE_OUTPUT_FILENAME = \"output.wav\"\n",
    "MP3_OUTPUT_FILENAME = \"output.mp3\"\n",
    "filename = \"output2.wav\"\n",
    "\n",
    "p = pyaudio.PyAudio()\n",
    "\n",
    "stream = p.open(format=FORMAT,\n",
    "                channels=CHANNELS,\n",
    "                rate=RATE,\n",
    "                input=True,\n",
    "                frames_per_buffer=CHUNK)\n",
    "\n",
    "print(\"* recording\")\n",
    "\n",
    "frames = []\n",
    "\n",
    "for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "    data = stream.read(CHUNK)\n",
    "    frames.append(data)\n",
    "\n",
    "# Stop and close the stream \n",
    "\n",
    "\n",
    "print(\"* done recording\")\n",
    "\n",
    "wf = wave.open(filename, 'wb')\n",
    "wf.setnchannels(CHANNELS)\n",
    "wf.setsampwidth(p.get_sample_size(FORMAT))\n",
    "wf.setframerate(RATE)\n",
    "wf.writeframes(b''.join(frames))\n",
    "wf.close()\n",
    "# Save recorded data as WAV file\n",
    "#with open(WAVE_OUTPUT_FILENAME, 'wb') as wf:\n",
    "#   wf.write(b''.join(frames))\n",
    "\n",
    "# Convert WAV to MP3 using pydub\n",
    "#sound = AudioSegment.from_wav(WAVE_OUTPUT_FILENAME)\n",
    "#sound.export(MP3_OUTPUT_FILENAME, format=\"mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install playsound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from playsound import playsound\n",
    "playsound('output2.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output.wav\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 2] The system cannot find the file specified",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[39mprint\u001b[39m (WAVE_OUTPUT_FILENAME)\n\u001b[0;32m      6\u001b[0m sound \u001b[39m=\u001b[39m AudioSegment\u001b[39m.\u001b[39mfrom_wav(\u001b[39m\"\u001b[39m\u001b[39mC:/Users/junwi/source/repos/jupy/openai/output2.wav\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m sound\u001b[39m.\u001b[39;49mexport(\u001b[39m\"\u001b[39;49m\u001b[39mC:/Users/junwi/source/repos/jupy/openai/audio.mp3\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mformat\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mmp3\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\junwi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pydub\\audio_segment.py:963\u001b[0m, in \u001b[0;36mAudioSegment.export\u001b[1;34m(self, out_f, format, codec, bitrate, parameters, tags, id3v2_version, cover)\u001b[0m\n\u001b[0;32m    961\u001b[0m \u001b[39m# read stdin / write stdout\u001b[39;00m\n\u001b[0;32m    962\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(os\u001b[39m.\u001b[39mdevnull, \u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m devnull:\n\u001b[1;32m--> 963\u001b[0m     p \u001b[39m=\u001b[39m subprocess\u001b[39m.\u001b[39;49mPopen(conversion_command, stdin\u001b[39m=\u001b[39;49mdevnull, stdout\u001b[39m=\u001b[39;49msubprocess\u001b[39m.\u001b[39;49mPIPE, stderr\u001b[39m=\u001b[39;49msubprocess\u001b[39m.\u001b[39;49mPIPE)\n\u001b[0;32m    964\u001b[0m p_out, p_err \u001b[39m=\u001b[39m p\u001b[39m.\u001b[39mcommunicate()\n\u001b[0;32m    966\u001b[0m log_subprocess_output(p_out)\n",
      "File \u001b[1;32mc:\\Users\\junwi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\subprocess.py:1024\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize, process_group)\u001b[0m\n\u001b[0;32m   1020\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtext_mode:\n\u001b[0;32m   1021\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39mTextIOWrapper(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr,\n\u001b[0;32m   1022\u001b[0m                     encoding\u001b[39m=\u001b[39mencoding, errors\u001b[39m=\u001b[39merrors)\n\u001b[1;32m-> 1024\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_execute_child(args, executable, preexec_fn, close_fds,\n\u001b[0;32m   1025\u001b[0m                         pass_fds, cwd, env,\n\u001b[0;32m   1026\u001b[0m                         startupinfo, creationflags, shell,\n\u001b[0;32m   1027\u001b[0m                         p2cread, p2cwrite,\n\u001b[0;32m   1028\u001b[0m                         c2pread, c2pwrite,\n\u001b[0;32m   1029\u001b[0m                         errread, errwrite,\n\u001b[0;32m   1030\u001b[0m                         restore_signals,\n\u001b[0;32m   1031\u001b[0m                         gid, gids, uid, umask,\n\u001b[0;32m   1032\u001b[0m                         start_new_session, process_group)\n\u001b[0;32m   1033\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m   1034\u001b[0m     \u001b[39m# Cleanup if the child failed starting.\u001b[39;00m\n\u001b[0;32m   1035\u001b[0m     \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m \u001b[39mfilter\u001b[39m(\u001b[39mNone\u001b[39;00m, (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstdin, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstdout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr)):\n",
      "File \u001b[1;32mc:\\Users\\junwi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\subprocess.py:1493\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_gid, unused_gids, unused_uid, unused_umask, unused_start_new_session, unused_process_group)\u001b[0m\n\u001b[0;32m   1491\u001b[0m \u001b[39m# Start the process\u001b[39;00m\n\u001b[0;32m   1492\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1493\u001b[0m     hp, ht, pid, tid \u001b[39m=\u001b[39m _winapi\u001b[39m.\u001b[39mCreateProcess(executable, args,\n\u001b[0;32m   1494\u001b[0m                              \u001b[39m# no special security\u001b[39;00m\n\u001b[0;32m   1495\u001b[0m                              \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   1496\u001b[0m                              \u001b[39mint\u001b[39m(\u001b[39mnot\u001b[39;00m close_fds),\n\u001b[0;32m   1497\u001b[0m                              creationflags,\n\u001b[0;32m   1498\u001b[0m                              env,\n\u001b[0;32m   1499\u001b[0m                              cwd,\n\u001b[0;32m   1500\u001b[0m                              startupinfo)\n\u001b[0;32m   1501\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m   1502\u001b[0m     \u001b[39m# Child is launched. Close the parent's copy of those pipe\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m     \u001b[39m# handles that only the child should have open.  You need\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1506\u001b[0m     \u001b[39m# pipe will not close when the child process exits and the\u001b[39;00m\n\u001b[0;32m   1507\u001b[0m     \u001b[39m# ReadFile will hang.\u001b[39;00m\n\u001b[0;32m   1508\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_close_pipe_fds(p2cread, p2cwrite,\n\u001b[0;32m   1509\u001b[0m                          c2pread, c2pwrite,\n\u001b[0;32m   1510\u001b[0m                          errread, errwrite)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified"
     ]
    }
   ],
   "source": [
    "# Convert WAV to MP3 using pydub\n",
    "import pyaudio\n",
    "from pydub import AudioSegment\n",
    "\n",
    "print (WAVE_OUTPUT_FILENAME)\n",
    "sound = AudioSegment.from_wav(\"C:/Users/junwi/source/repos/jupy/openai/output2.wav\")\n",
    "sound.export(\"C:/Users/junwi/source/repos/jupy/openai/audio.mp3\", format=\"mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "AuthenticationError",
     "evalue": "No API key provided. You can set your API key in code using 'openai.api_key = <API-KEY>', or you can set the environment variable OPENAI_API_KEY=<API-KEY>). If your API key is stored in a file, you can point the openai module at it with 'openai.api_key_path = <PATH>'. You can generate API keys in the OpenAI web interface. See https://onboard.openai.com for details, or email support@openai.com if you have any questions.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 12\u001b[0m\n\u001b[0;32m      6\u001b[0m headers \u001b[39m=\u001b[39m {\n\u001b[0;32m      7\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mContent-Type\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mapplication/json\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m      8\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mAuthorization\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mBearer \u001b[39m\u001b[39m{\u001b[39;00mapi_key\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[0;32m      9\u001b[0m }\n\u001b[0;32m     11\u001b[0m audio_file\u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mC:/Users/junwi/source/repos/jupy/openai/output2.wav\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 12\u001b[0m transcript \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39;49mAudio\u001b[39m.\u001b[39;49mtranscribe(\u001b[39m\"\u001b[39;49m\u001b[39mwhisper-1\u001b[39;49m\u001b[39m\"\u001b[39;49m, audio_file)\n",
      "File \u001b[1;32mc:\\Users\\junwi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\api_resources\\audio.py:55\u001b[0m, in \u001b[0;36mAudio.transcribe\u001b[1;34m(cls, model, file, api_key, api_base, api_type, api_version, organization, **params)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m     44\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtranscribe\u001b[39m(\n\u001b[0;32m     45\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[0;32m     54\u001b[0m ):\n\u001b[1;32m---> 55\u001b[0m     requestor, files, data \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_prepare_request(file, file\u001b[39m.\u001b[39;49mname, model, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams)\n\u001b[0;32m     56\u001b[0m     url \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_get_url(\u001b[39m\"\u001b[39m\u001b[39mtranscriptions\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     57\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39mrequest(\u001b[39m\"\u001b[39m\u001b[39mpost\u001b[39m\u001b[39m\"\u001b[39m, url, files\u001b[39m=\u001b[39mfiles, params\u001b[39m=\u001b[39mdata)\n",
      "File \u001b[1;32mc:\\Users\\junwi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\api_resources\\audio.py:28\u001b[0m, in \u001b[0;36mAudio._prepare_request\u001b[1;34m(cls, file, filename, model, api_key, api_base, api_type, api_version, organization, **params)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m     16\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_prepare_request\u001b[39m(\n\u001b[0;32m     17\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[0;32m     27\u001b[0m ):\n\u001b[1;32m---> 28\u001b[0m     requestor \u001b[39m=\u001b[39m api_requestor\u001b[39m.\u001b[39;49mAPIRequestor(\n\u001b[0;32m     29\u001b[0m         api_key,\n\u001b[0;32m     30\u001b[0m         api_base\u001b[39m=\u001b[39;49mapi_base \u001b[39mor\u001b[39;49;00m openai\u001b[39m.\u001b[39;49mapi_base,\n\u001b[0;32m     31\u001b[0m         api_type\u001b[39m=\u001b[39;49mapi_type,\n\u001b[0;32m     32\u001b[0m         api_version\u001b[39m=\u001b[39;49mapi_version,\n\u001b[0;32m     33\u001b[0m         organization\u001b[39m=\u001b[39;49morganization,\n\u001b[0;32m     34\u001b[0m     )\n\u001b[0;32m     35\u001b[0m     files: List[Any] \u001b[39m=\u001b[39m []\n\u001b[0;32m     36\u001b[0m     data \u001b[39m=\u001b[39m {\n\u001b[0;32m     37\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m: model,\n\u001b[0;32m     38\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[0;32m     39\u001b[0m     }\n",
      "File \u001b[1;32mc:\\Users\\junwi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\api_requestor.py:130\u001b[0m, in \u001b[0;36mAPIRequestor.__init__\u001b[1;34m(self, key, api_base, api_type, api_version, organization)\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[0;32m    122\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    123\u001b[0m     key\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    127\u001b[0m     organization\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    128\u001b[0m ):\n\u001b[0;32m    129\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_base \u001b[39m=\u001b[39m api_base \u001b[39mor\u001b[39;00m openai\u001b[39m.\u001b[39mapi_base\n\u001b[1;32m--> 130\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key \u001b[39m=\u001b[39m key \u001b[39mor\u001b[39;00m util\u001b[39m.\u001b[39;49mdefault_api_key()\n\u001b[0;32m    131\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_type \u001b[39m=\u001b[39m (\n\u001b[0;32m    132\u001b[0m         ApiType\u001b[39m.\u001b[39mfrom_str(api_type)\n\u001b[0;32m    133\u001b[0m         \u001b[39mif\u001b[39;00m api_type\n\u001b[0;32m    134\u001b[0m         \u001b[39melse\u001b[39;00m ApiType\u001b[39m.\u001b[39mfrom_str(openai\u001b[39m.\u001b[39mapi_type)\n\u001b[0;32m    135\u001b[0m     )\n\u001b[0;32m    136\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_version \u001b[39m=\u001b[39m api_version \u001b[39mor\u001b[39;00m openai\u001b[39m.\u001b[39mapi_version\n",
      "File \u001b[1;32mc:\\Users\\junwi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\util.py:186\u001b[0m, in \u001b[0;36mdefault_api_key\u001b[1;34m()\u001b[0m\n\u001b[0;32m    184\u001b[0m     \u001b[39mreturn\u001b[39;00m openai\u001b[39m.\u001b[39mapi_key\n\u001b[0;32m    185\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 186\u001b[0m     \u001b[39mraise\u001b[39;00m openai\u001b[39m.\u001b[39merror\u001b[39m.\u001b[39mAuthenticationError(\n\u001b[0;32m    187\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo API key provided. You can set your API key in code using \u001b[39m\u001b[39m'\u001b[39m\u001b[39mopenai.api_key = <API-KEY>\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, or you can set the environment variable OPENAI_API_KEY=<API-KEY>). If your API key is stored in a file, you can point the openai module at it with \u001b[39m\u001b[39m'\u001b[39m\u001b[39mopenai.api_key_path = <PATH>\u001b[39m\u001b[39m'\u001b[39m\u001b[39m. You can generate API keys in the OpenAI web interface. See https://onboard.openai.com for details, or email support@openai.com if you have any questions.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    188\u001b[0m     )\n",
      "\u001b[1;31mAuthenticationError\u001b[0m: No API key provided. You can set your API key in code using 'openai.api_key = <API-KEY>', or you can set the environment variable OPENAI_API_KEY=<API-KEY>). If your API key is stored in a file, you can point the openai module at it with 'openai.api_key_path = <PATH>'. You can generate API keys in the OpenAI web interface. See https://onboard.openai.com for details, or email support@openai.com if you have any questions."
     ]
    }
   ],
   "source": [
    "# Note: you need to be using OpenAI Python v0.27.0 for the code below to work\n",
    "import openai\n",
    "# Replace 'your_api_key_here' with your actual API key\n",
    "api_key = \"zzzzzzzzzzzzzzzzzzzzzzzz\"\n",
    "\n",
    "headers = {\n",
    "    'Content-Type': 'application/json',\n",
    "    'Authorization': f'Bearer {api_key}'\n",
    "}\n",
    "\n",
    "audio_file= open(\"C:/Users/junwi/source/repos/jupy/openai/output2.wav\", \"rb\")\n",
    "transcript = openai.Audio.transcribe(\"whisper-1\", audio_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
