{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on code from Lawrence Moroney  https://laurencemoroney.com/about.html \n",
    "\n",
    "It uses an existing model (inception) and augments it to detect pictures of horses and humans\n",
    "and reuses key parts of inception e.g. extracting convolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import Model\n",
    "from keras import layers\n",
    "from os import getcwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_path = f\"C:/Users/junwi/source/sandpit/cnn_lawrence/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1xJZ5glPPCRz"
   },
   "outputs": [],
   "source": [
    "path_inception = work_path + f\"tmp2/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n",
    "\n",
    "# Import the inception model  \n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "# Create an instance of the inception model from the local pre-trained weights\n",
    "local_weights_file = path_inception\n",
    "\n",
    "pre_trained_model = InceptionV3(input_shape = (150, 150, 3), \n",
    "                                include_top = False, \n",
    "                                weights = None) \n",
    "\n",
    "pre_trained_model.load_weights(local_weights_file)\n",
    "\n",
    "# Make all the layers in the pre-trained model non-trainable\n",
    "for layer in pre_trained_model.layers:\n",
    "  layer.trainable = False \n",
    "  \n",
    "# Print the model summary\n",
    "pre_trained_model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CFsUlwdfs_wg"
   },
   "outputs": [],
   "source": [
    "last_layer = pre_trained_model.get_layer('mixed7')\n",
    "print('last layer output shape: ', last_layer.output_shape)\n",
    "last_output = last_layer.output\n",
    "\n",
    "# Expected Output:\n",
    "# ('last layer output shape: ', (None, 7, 7, 768))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-bsWZWp5oMq9"
   },
   "outputs": [],
   "source": [
    "# Define a Callback class that stops training once accuracy reaches 97.0%\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    if(logs.get('acc')>0.97):\n",
    "      print(\"\\nReached 97.0% accuracy so cancelling training!\")\n",
    "      self.model.stop_training = True\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BMXb913pbvFg"
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import RMSprop\n",
    "\n",
    "# Flatten the output layer to 1 dimension\n",
    "x = layers.Flatten()(last_output)\n",
    "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
    "x = layers.Dense(1024, activation='relu')(x)\n",
    "# Add a dropout rate of 0.2\n",
    "x = layers.Dropout(0.2)(x)                  \n",
    "# Add a final sigmoid layer for classification\n",
    "x = layers.Dense  (1, activation='sigmoid')(x)           \n",
    "\n",
    "model = Model( pre_trained_model.input, x) \n",
    "\n",
    "model.compile(optimizer = RMSprop(lr=0.0001), \n",
    "              loss = 'binary_crossentropy', \n",
    "              metrics = ['acc'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HrnL_IQ8knWA"
   },
   "outputs": [],
   "source": [
    "# Get the Horse or Human dataset\n",
    "path_horse_or_human = f\"C:/Users/junwi/Downloads/horse-or-human.zip\"\n",
    "# Get the Horse or Human Validation dataset\n",
    "path_validation_horse_or_human = f\"C:/Users/junwi/Downloads/validation-horse-or-human.zip\"\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import os\n",
    "import zipfile\n",
    "import shutil\n",
    "\n",
    "shutil.rmtree(work_path +'tmp')\n",
    "local_zip = path_horse_or_human\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall(work_path + 'tmp/training')\n",
    "zip_ref.close()\n",
    "\n",
    "local_zip = path_validation_horse_or_human\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall(work_path + 'tmp/validation')\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y9okX7_ovskI"
   },
   "outputs": [],
   "source": [
    "# Define our example directories and files\n",
    "train_dir = work_path +'tmp/training'\n",
    "validation_dir = work_path +'tmp/validation'\n",
    "\n",
    "train_horses_dir = train_dir + '/horses'\n",
    "train_humans_dir = train_dir +  '/humans'\n",
    "validation_horses_dir = validation_dir + '/horses'\n",
    "validation_humans_dir = validation_dir + '/humans'\n",
    "\n",
    "train_horses_fnames = os.listdir(train_horses_dir) \n",
    "train_humans_fnames = os.listdir(train_humans_dir) \n",
    "validation_horses_fnames = os.listdir(validation_horses_dir) \n",
    "validation_humans_fnames = os.listdir(validation_humans_dir) \n",
    "\n",
    "print(len(train_horses_fnames))\n",
    "print(len(train_humans_fnames)) \n",
    "print(len(validation_horses_fnames))\n",
    "print(len(validation_humans_fnames))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    rescale: This rescales the pixel values of the images so that they are between 0 and 1. This is a common preprocessing step for image data, as it can make it easier for the model to learn the underlying patterns in the data.\n",
    "\n",
    "    rotation_range: This randomly rotates the images by a certain number of degrees. In this case, the range is set to 40 degrees, which means that the images can be rotated by up to 40 degrees in either direction.\n",
    "\n",
    "    width_shift_range and height_shift_range: These randomly shift the images horizontally and vertically by a certain percentage of their width and height. In this case, the range is set to 0.2, which means that the images can be shifted by up to 20% of their width or height.\n",
    "\n",
    "    shear_range: This randomly applies a shear transformation to the images, which distorts them along one axis while keeping the other axis fixed. In this case, the range is set to 0.2, which means that the images can be sheared by up to 20% of their width or height.\n",
    "\n",
    "    zoom_range: This randomly applies a zoom transformation to the images, which either zooms in or out on the image. In this case, the range is set to 0.2, which means that the images can be zoomed in or out by up to 20%.\n",
    "\n",
    "    horizontal_flip: This randomly flips the images horizontally. This can help introduce more variety in the training data, as it effectively doubles the number of images by providing a mirror image for each original image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O4s8HckqGlnb"
   },
   "outputs": [],
   "source": [
    "# Add our data-augmentation parameters to ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(ImageDataGenerator(rescale = 1./255.,\n",
    "                                   rotation_range = 40,\n",
    "                                   width_shift_range = 0.2,\n",
    "                                   height_shift_range = 0.2,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True))\n",
    "\n",
    "train_datagen2 = ImageDataGenerator( rescale = 1.0/255., rotation_range = 40, width_shift_range = 0.2,\n",
    "                                    height_shift_range = 0.2, shear_range = 0.2,\n",
    "                                    zoom_range = 0.2, horizontal_flip = True)\n",
    "\n",
    "# Flow training images in batches of 20 using train_datagen generator\n",
    "train_generator = train_datagen2.flow_from_directory(train_dir,\n",
    "                                                    batch_size = 20,\n",
    "                                                    class_mode = 'binary', \n",
    "                                                    target_size = (150, 150))\n",
    "\n",
    "# Note that the validation data should not be augmented!\n",
    "#test_datagen = ImageDataGenerator( rescale = 1.0/255.  )\n",
    "validation_datagen = ImageDataGenerator( rescale = 1.0/255.  )\n",
    "\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(validation_dir,\n",
    "                                                              target_size=(150, 150),\n",
    "                                                              batch_size=20,\n",
    "                                                              class_mode='binary')\n",
    "\n",
    "\n",
    "# Flow validation images in batches of 20 using test_datagen generator\n",
    "#validation_generator =  test_datagen.flow_from_directory(  validation_dir, batch_size  = 20,class_mode  = 'binary',target_size = (150, 150))\n",
    "\n",
    "# Expected Output:\n",
    "# Found 1027 images belonging to 2 classes.\n",
    "# Found 256 images belonging to 2 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model( pre_trained_model.input, x) \n",
    "\n",
    "model.compile(optimizer = RMSprop(lr=0.0001), \n",
    "              loss = 'binary_crossentropy', \n",
    "              metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Blhq2MAUeyGA"
   },
   "outputs": [],
   "source": [
    "# Run this and see how many epochs it should take before the callback\n",
    "# fires, and stops training at 97% accuracy\n",
    "\n",
    "callbacks = myCallback()\n",
    "history = model.fit(\n",
    "            train_generator,\n",
    "            validation_data = validation_generator,\n",
    "            steps_per_epoch = 50,\n",
    "            epochs = 2,\n",
    "            validation_steps = 10,\n",
    "            verbose = 2,\n",
    "            callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C2Fp6Se9rKuL"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend(loc=0)\n",
    "plt.figure()\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# detecting if a picture is a horse or human\n",
    "\n",
    "recall that -  if we have two folders named \"horses\" and \"humans\", the flow_from_directory function will assign binary label 0 to the \"horses\" category and binary label 1 to the \"humans\" category. This is because \"horses\" comes first alphabetically, so it gets assigned the label 0, and \"humans\" comes second, so it gets assigned the label 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "# image_path = work_path + f\"tmp/validation/humans/valhuman02-01.png\"\n",
    "image_path =  work_path + f\"tmp/training/horses/horse01-8.png\"\n",
    "image = keras.preprocessing.image.load_img(image_path, target_size=(150, 150))\n",
    "import numpy as np\n",
    "\n",
    "image_array = keras.preprocessing.image.img_to_array(image)\n",
    "image_array = np.expand_dims(image_array, axis=0)\n",
    "image_array /= 255.0\n",
    "\n",
    "prediction = model.predict(image_array)\n",
    "\n",
    "predicted_class = \"humans\" if prediction[0] > 0.5 else \"other_class\"\n",
    "print(f\"The predicted class is: {predicted_class}\")\n",
    "print(f\"The prediction is: {prediction[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Load the saved model\n",
    "# model = keras.models.load_model(\"my_model.h5\")\n",
    "\n",
    "# Define the path to the folder containing the images to predict\n",
    "folder_path = work_path + f\"tmp/training/humans\"\n",
    "\n",
    "# Create a list of all the image file names in the folder\n",
    "file_names = os.listdir(folder_path)\n",
    "\n",
    "# Loop through each image file and make a prediction\n",
    "for file_name in file_names:\n",
    "    # Load the image and preprocess it\n",
    "    image_path = os.path.join(folder_path, file_name)\n",
    "    image = keras.preprocessing.image.load_img(image_path, target_size=(150, 150))\n",
    "    image_array = keras.preprocessing.image.img_to_array(image)\n",
    "    image_array = np.expand_dims(image_array, axis=0)\n",
    "    image_array /= 255.0\n",
    "    \n",
    "    # Make the prediction\n",
    "    prediction = model.predict(image_array)\n",
    "    \n",
    "    # Print the file name and prediction\n",
    "    print(f\"{file_name}: {prediction[0]}\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Exercise 7 - Question.ipynb",
   "provenance": []
  },
  "coursera": {
   "course_slug": "convolutional-neural-networks-tensorflow",
   "graded_item_id": "csg1x",
   "launcher_item_id": "GpKYz"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
