{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lbFmQdsZs5eW"
   },
   "outputs": [],
   "source": [
    "\n",
    "# %pip install tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import Model\n",
    "from keras import layers\n",
    "# from tensorflow.keras import layers\n",
    "# from tensorflow.keras import Model\n",
    "from os import getcwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_path = f\"C:/Users/junwi/source/sandpit/cnn_lawrence/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1xJZ5glPPCRz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"inception_v3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 150, 150, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 74, 74, 32)   864         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 74, 74, 32)  96          ['conv2d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 74, 74, 32)   0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 72, 72, 32)   9216        ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 72, 72, 32)  96          ['conv2d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 72, 72, 32)   0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 72, 72, 64)   18432       ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 72, 72, 64)  192         ['conv2d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 72, 72, 64)   0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 35, 35, 64)   0           ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 35, 35, 80)   5120        ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 35, 35, 80)  240         ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 35, 35, 80)   0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 33, 33, 192)  138240      ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 33, 33, 192)  576        ['conv2d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 33, 33, 192)  0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0          ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 16, 16, 64)   12288       ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 16, 16, 64)  192         ['conv2d_8[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 16, 16, 64)   0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 16, 16, 48)   9216        ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 16, 16, 96)   55296       ['activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 16, 16, 48)  144         ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 16, 16, 96)  288         ['conv2d_9[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 16, 16, 48)   0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 16, 16, 96)   0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " average_pooling2d (AveragePool  (None, 16, 16, 192)  0          ['max_pooling2d_1[0][0]']        \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 16, 16, 64)   12288       ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 16, 16, 64)   76800       ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 16, 16, 96)   82944       ['activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 16, 16, 32)   6144        ['average_pooling2d[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 16, 16, 64)  192         ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 16, 16, 64)  192         ['conv2d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 16, 16, 96)  288         ['conv2d_10[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 16, 16, 32)  96          ['conv2d_11[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 16, 16, 64)   0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 16, 16, 64)   0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 16, 16, 96)   0           ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 16, 16, 32)   0           ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " mixed0 (Concatenate)           (None, 16, 16, 256)  0           ['activation_5[0][0]',           \n",
      "                                                                  'activation_7[0][0]',           \n",
      "                                                                  'activation_10[0][0]',          \n",
      "                                                                  'activation_11[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 16, 16, 64)   16384       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 16, 16, 64)  192         ['conv2d_15[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_15 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 16, 16, 48)   12288       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 16, 16, 96)   55296       ['activation_15[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 16, 16, 48)  144         ['conv2d_13[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 16, 16, 96)  288         ['conv2d_16[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_13 (Activation)     (None, 16, 16, 48)   0           ['batch_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " activation_16 (Activation)     (None, 16, 16, 96)   0           ['batch_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_1 (AveragePo  (None, 16, 16, 256)  0          ['mixed0[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 16, 16, 64)   16384       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 16, 16, 64)   76800       ['activation_13[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 16, 16, 96)   82944       ['activation_16[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 16, 16, 64)   16384       ['average_pooling2d_1[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 16, 16, 64)  192         ['conv2d_12[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 16, 16, 64)  192         ['conv2d_14[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 16, 16, 96)  288         ['conv2d_17[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 16, 16, 64)  192         ['conv2d_18[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " activation_14 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " activation_17 (Activation)     (None, 16, 16, 96)   0           ['batch_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " activation_18 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " mixed1 (Concatenate)           (None, 16, 16, 288)  0           ['activation_12[0][0]',          \n",
      "                                                                  'activation_14[0][0]',          \n",
      "                                                                  'activation_17[0][0]',          \n",
      "                                                                  'activation_18[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)             (None, 16, 16, 64)   18432       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_22 (BatchN  (None, 16, 16, 64)  192         ['conv2d_22[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_22 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_22[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, 16, 16, 48)   13824       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)             (None, 16, 16, 96)   55296       ['activation_22[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_20 (BatchN  (None, 16, 16, 48)  144         ['conv2d_20[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_23 (BatchN  (None, 16, 16, 96)  288         ['conv2d_23[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_20 (Activation)     (None, 16, 16, 48)   0           ['batch_normalization_20[0][0]'] \n",
      "                                                                                                  \n",
      " activation_23 (Activation)     (None, 16, 16, 96)   0           ['batch_normalization_23[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_2 (AveragePo  (None, 16, 16, 288)  0          ['mixed1[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 16, 16, 64)   18432       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)             (None, 16, 16, 64)   76800       ['activation_20[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)             (None, 16, 16, 96)   82944       ['activation_23[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)             (None, 16, 16, 64)   18432       ['average_pooling2d_2[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_19 (BatchN  (None, 16, 16, 64)  192         ['conv2d_19[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_21 (BatchN  (None, 16, 16, 64)  192         ['conv2d_21[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_24 (BatchN  (None, 16, 16, 96)  288         ['conv2d_24[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_25 (BatchN  (None, 16, 16, 64)  192         ['conv2d_25[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_19 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_19[0][0]'] \n",
      "                                                                                                  \n",
      " activation_21 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_21[0][0]'] \n",
      "                                                                                                  \n",
      " activation_24 (Activation)     (None, 16, 16, 96)   0           ['batch_normalization_24[0][0]'] \n",
      "                                                                                                  \n",
      " activation_25 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_25[0][0]'] \n",
      "                                                                                                  \n",
      " mixed2 (Concatenate)           (None, 16, 16, 288)  0           ['activation_19[0][0]',          \n",
      "                                                                  'activation_21[0][0]',          \n",
      "                                                                  'activation_24[0][0]',          \n",
      "                                                                  'activation_25[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)             (None, 16, 16, 64)   18432       ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_27 (BatchN  (None, 16, 16, 64)  192         ['conv2d_27[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_27 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_27[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_28 (Conv2D)             (None, 16, 16, 96)   55296       ['activation_27[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_28 (BatchN  (None, 16, 16, 96)  288         ['conv2d_28[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_28 (Activation)     (None, 16, 16, 96)   0           ['batch_normalization_28[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)             (None, 7, 7, 384)    995328      ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_29 (Conv2D)             (None, 7, 7, 96)     82944       ['activation_28[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_26 (BatchN  (None, 7, 7, 384)   1152        ['conv2d_26[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_29 (BatchN  (None, 7, 7, 96)    288         ['conv2d_29[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_26 (Activation)     (None, 7, 7, 384)    0           ['batch_normalization_26[0][0]'] \n",
      "                                                                                                  \n",
      " activation_29 (Activation)     (None, 7, 7, 96)     0           ['batch_normalization_29[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)   0           ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " mixed3 (Concatenate)           (None, 7, 7, 768)    0           ['activation_26[0][0]',          \n",
      "                                                                  'activation_29[0][0]',          \n",
      "                                                                  'max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_34 (Conv2D)             (None, 7, 7, 128)    98304       ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_34 (BatchN  (None, 7, 7, 128)   384         ['conv2d_34[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_34 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_34[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_35 (Conv2D)             (None, 7, 7, 128)    114688      ['activation_34[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_35 (BatchN  (None, 7, 7, 128)   384         ['conv2d_35[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_35 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_35[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_31 (Conv2D)             (None, 7, 7, 128)    98304       ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_36 (Conv2D)             (None, 7, 7, 128)    114688      ['activation_35[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_31 (BatchN  (None, 7, 7, 128)   384         ['conv2d_31[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_36 (BatchN  (None, 7, 7, 128)   384         ['conv2d_36[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_31 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_31[0][0]'] \n",
      "                                                                                                  \n",
      " activation_36 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_36[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_32 (Conv2D)             (None, 7, 7, 128)    114688      ['activation_31[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_37 (Conv2D)             (None, 7, 7, 128)    114688      ['activation_36[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_32 (BatchN  (None, 7, 7, 128)   384         ['conv2d_32[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_37 (BatchN  (None, 7, 7, 128)   384         ['conv2d_37[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_32 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_32[0][0]'] \n",
      "                                                                                                  \n",
      " activation_37 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_37[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_3 (AveragePo  (None, 7, 7, 768)   0           ['mixed3[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_33 (Conv2D)             (None, 7, 7, 192)    172032      ['activation_32[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_38 (Conv2D)             (None, 7, 7, 192)    172032      ['activation_37[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_39 (Conv2D)             (None, 7, 7, 192)    147456      ['average_pooling2d_3[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_30 (BatchN  (None, 7, 7, 192)   576         ['conv2d_30[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_33 (BatchN  (None, 7, 7, 192)   576         ['conv2d_33[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_38 (BatchN  (None, 7, 7, 192)   576         ['conv2d_38[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_39 (BatchN  (None, 7, 7, 192)   576         ['conv2d_39[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_30 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_30[0][0]'] \n",
      "                                                                                                  \n",
      " activation_33 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_33[0][0]'] \n",
      "                                                                                                  \n",
      " activation_38 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_38[0][0]'] \n",
      "                                                                                                  \n",
      " activation_39 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_39[0][0]'] \n",
      "                                                                                                  \n",
      " mixed4 (Concatenate)           (None, 7, 7, 768)    0           ['activation_30[0][0]',          \n",
      "                                                                  'activation_33[0][0]',          \n",
      "                                                                  'activation_38[0][0]',          \n",
      "                                                                  'activation_39[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_44 (Conv2D)             (None, 7, 7, 160)    122880      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_44 (BatchN  (None, 7, 7, 160)   480         ['conv2d_44[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_44 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_44[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_45 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_44[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_45 (BatchN  (None, 7, 7, 160)   480         ['conv2d_45[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_45 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_45[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_41 (Conv2D)             (None, 7, 7, 160)    122880      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_46 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_45[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_41 (BatchN  (None, 7, 7, 160)   480         ['conv2d_41[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_46 (BatchN  (None, 7, 7, 160)   480         ['conv2d_46[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_41 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_41[0][0]'] \n",
      "                                                                                                  \n",
      " activation_46 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_46[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_42 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_41[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_47 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_46[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_42 (BatchN  (None, 7, 7, 160)   480         ['conv2d_42[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_47 (BatchN  (None, 7, 7, 160)   480         ['conv2d_47[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_42 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_42[0][0]'] \n",
      "                                                                                                  \n",
      " activation_47 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_47[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_4 (AveragePo  (None, 7, 7, 768)   0           ['mixed4[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_40 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_43 (Conv2D)             (None, 7, 7, 192)    215040      ['activation_42[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_48 (Conv2D)             (None, 7, 7, 192)    215040      ['activation_47[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_49 (Conv2D)             (None, 7, 7, 192)    147456      ['average_pooling2d_4[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_40 (BatchN  (None, 7, 7, 192)   576         ['conv2d_40[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_43 (BatchN  (None, 7, 7, 192)   576         ['conv2d_43[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_48 (BatchN  (None, 7, 7, 192)   576         ['conv2d_48[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_49 (BatchN  (None, 7, 7, 192)   576         ['conv2d_49[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_40 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_40[0][0]'] \n",
      "                                                                                                  \n",
      " activation_43 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_43[0][0]'] \n",
      "                                                                                                  \n",
      " activation_48 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_48[0][0]'] \n",
      "                                                                                                  \n",
      " activation_49 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_49[0][0]'] \n",
      "                                                                                                  \n",
      " mixed5 (Concatenate)           (None, 7, 7, 768)    0           ['activation_40[0][0]',          \n",
      "                                                                  'activation_43[0][0]',          \n",
      "                                                                  'activation_48[0][0]',          \n",
      "                                                                  'activation_49[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_54 (Conv2D)             (None, 7, 7, 160)    122880      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_54 (BatchN  (None, 7, 7, 160)   480         ['conv2d_54[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_54 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_54[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_55 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_54[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_55 (BatchN  (None, 7, 7, 160)   480         ['conv2d_55[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_55 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_55[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_51 (Conv2D)             (None, 7, 7, 160)    122880      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_56 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_55[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_51 (BatchN  (None, 7, 7, 160)   480         ['conv2d_51[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_56 (BatchN  (None, 7, 7, 160)   480         ['conv2d_56[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_51 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_51[0][0]'] \n",
      "                                                                                                  \n",
      " activation_56 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_56[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_52 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_51[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_57 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_56[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_52 (BatchN  (None, 7, 7, 160)   480         ['conv2d_52[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_57 (BatchN  (None, 7, 7, 160)   480         ['conv2d_57[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_52 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_52[0][0]'] \n",
      "                                                                                                  \n",
      " activation_57 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_57[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_5 (AveragePo  (None, 7, 7, 768)   0           ['mixed5[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_50 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_53 (Conv2D)             (None, 7, 7, 192)    215040      ['activation_52[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_58 (Conv2D)             (None, 7, 7, 192)    215040      ['activation_57[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_59 (Conv2D)             (None, 7, 7, 192)    147456      ['average_pooling2d_5[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_50 (BatchN  (None, 7, 7, 192)   576         ['conv2d_50[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_53 (BatchN  (None, 7, 7, 192)   576         ['conv2d_53[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_58 (BatchN  (None, 7, 7, 192)   576         ['conv2d_58[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_59 (BatchN  (None, 7, 7, 192)   576         ['conv2d_59[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_50 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_50[0][0]'] \n",
      "                                                                                                  \n",
      " activation_53 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_53[0][0]'] \n",
      "                                                                                                  \n",
      " activation_58 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_58[0][0]'] \n",
      "                                                                                                  \n",
      " activation_59 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_59[0][0]'] \n",
      "                                                                                                  \n",
      " mixed6 (Concatenate)           (None, 7, 7, 768)    0           ['activation_50[0][0]',          \n",
      "                                                                  'activation_53[0][0]',          \n",
      "                                                                  'activation_58[0][0]',          \n",
      "                                                                  'activation_59[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_64 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_64 (BatchN  (None, 7, 7, 192)   576         ['conv2d_64[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_64 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_64[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_65 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_64[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_65 (BatchN  (None, 7, 7, 192)   576         ['conv2d_65[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_65 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_65[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_61 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_66 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_65[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_61 (BatchN  (None, 7, 7, 192)   576         ['conv2d_61[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_66 (BatchN  (None, 7, 7, 192)   576         ['conv2d_66[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_61 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_61[0][0]'] \n",
      "                                                                                                  \n",
      " activation_66 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_66[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_62 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_61[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_67 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_66[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_62 (BatchN  (None, 7, 7, 192)   576         ['conv2d_62[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_67 (BatchN  (None, 7, 7, 192)   576         ['conv2d_67[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_62 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_62[0][0]'] \n",
      "                                                                                                  \n",
      " activation_67 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_67[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_6 (AveragePo  (None, 7, 7, 768)   0           ['mixed6[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_60 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_63 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_62[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_68 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_67[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_69 (Conv2D)             (None, 7, 7, 192)    147456      ['average_pooling2d_6[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_60 (BatchN  (None, 7, 7, 192)   576         ['conv2d_60[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_63 (BatchN  (None, 7, 7, 192)   576         ['conv2d_63[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_68 (BatchN  (None, 7, 7, 192)   576         ['conv2d_68[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_69 (BatchN  (None, 7, 7, 192)   576         ['conv2d_69[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_60 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_60[0][0]'] \n",
      "                                                                                                  \n",
      " activation_63 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_63[0][0]'] \n",
      "                                                                                                  \n",
      " activation_68 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_68[0][0]'] \n",
      "                                                                                                  \n",
      " activation_69 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_69[0][0]'] \n",
      "                                                                                                  \n",
      " mixed7 (Concatenate)           (None, 7, 7, 768)    0           ['activation_60[0][0]',          \n",
      "                                                                  'activation_63[0][0]',          \n",
      "                                                                  'activation_68[0][0]',          \n",
      "                                                                  'activation_69[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_72 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed7[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_72 (BatchN  (None, 7, 7, 192)   576         ['conv2d_72[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_72 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_72[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_73 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_72[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_73 (BatchN  (None, 7, 7, 192)   576         ['conv2d_73[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_73 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_73[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_70 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed7[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_74 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_73[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_70 (BatchN  (None, 7, 7, 192)   576         ['conv2d_70[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_74 (BatchN  (None, 7, 7, 192)   576         ['conv2d_74[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_70 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_70[0][0]'] \n",
      "                                                                                                  \n",
      " activation_74 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_74[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_71 (Conv2D)             (None, 3, 3, 320)    552960      ['activation_70[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_75 (Conv2D)             (None, 3, 3, 192)    331776      ['activation_74[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_71 (BatchN  (None, 3, 3, 320)   960         ['conv2d_71[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_75 (BatchN  (None, 3, 3, 192)   576         ['conv2d_75[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_71 (Activation)     (None, 3, 3, 320)    0           ['batch_normalization_71[0][0]'] \n",
      "                                                                                                  \n",
      " activation_75 (Activation)     (None, 3, 3, 192)    0           ['batch_normalization_75[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 3, 3, 768)   0           ['mixed7[0][0]']                 \n",
      "                                                                                                  \n",
      " mixed8 (Concatenate)           (None, 3, 3, 1280)   0           ['activation_71[0][0]',          \n",
      "                                                                  'activation_75[0][0]',          \n",
      "                                                                  'max_pooling2d_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_80 (Conv2D)             (None, 3, 3, 448)    573440      ['mixed8[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_80 (BatchN  (None, 3, 3, 448)   1344        ['conv2d_80[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_80 (Activation)     (None, 3, 3, 448)    0           ['batch_normalization_80[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_77 (Conv2D)             (None, 3, 3, 384)    491520      ['mixed8[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_81 (Conv2D)             (None, 3, 3, 384)    1548288     ['activation_80[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_77 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_77[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_81 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_81[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_77 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_77[0][0]'] \n",
      "                                                                                                  \n",
      " activation_81 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_81[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_78 (Conv2D)             (None, 3, 3, 384)    442368      ['activation_77[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_79 (Conv2D)             (None, 3, 3, 384)    442368      ['activation_77[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_82 (Conv2D)             (None, 3, 3, 384)    442368      ['activation_81[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_83 (Conv2D)             (None, 3, 3, 384)    442368      ['activation_81[0][0]']          \n",
      "                                                                                                  \n",
      " average_pooling2d_7 (AveragePo  (None, 3, 3, 1280)  0           ['mixed8[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_76 (Conv2D)             (None, 3, 3, 320)    409600      ['mixed8[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_78 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_78[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_79 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_79[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_82 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_82[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_83 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_83[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_84 (Conv2D)             (None, 3, 3, 192)    245760      ['average_pooling2d_7[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_76 (BatchN  (None, 3, 3, 320)   960         ['conv2d_76[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_78 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_78[0][0]'] \n",
      "                                                                                                  \n",
      " activation_79 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_79[0][0]'] \n",
      "                                                                                                  \n",
      " activation_82 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_82[0][0]'] \n",
      "                                                                                                  \n",
      " activation_83 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_83[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_84 (BatchN  (None, 3, 3, 192)   576         ['conv2d_84[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_76 (Activation)     (None, 3, 3, 320)    0           ['batch_normalization_76[0][0]'] \n",
      "                                                                                                  \n",
      " mixed9_0 (Concatenate)         (None, 3, 3, 768)    0           ['activation_78[0][0]',          \n",
      "                                                                  'activation_79[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 3, 3, 768)    0           ['activation_82[0][0]',          \n",
      "                                                                  'activation_83[0][0]']          \n",
      "                                                                                                  \n",
      " activation_84 (Activation)     (None, 3, 3, 192)    0           ['batch_normalization_84[0][0]'] \n",
      "                                                                                                  \n",
      " mixed9 (Concatenate)           (None, 3, 3, 2048)   0           ['activation_76[0][0]',          \n",
      "                                                                  'mixed9_0[0][0]',               \n",
      "                                                                  'concatenate[0][0]',            \n",
      "                                                                  'activation_84[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_89 (Conv2D)             (None, 3, 3, 448)    917504      ['mixed9[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_89 (BatchN  (None, 3, 3, 448)   1344        ['conv2d_89[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_89 (Activation)     (None, 3, 3, 448)    0           ['batch_normalization_89[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_86 (Conv2D)             (None, 3, 3, 384)    786432      ['mixed9[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_90 (Conv2D)             (None, 3, 3, 384)    1548288     ['activation_89[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_86 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_86[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_90 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_90[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_86 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_86[0][0]'] \n",
      "                                                                                                  \n",
      " activation_90 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_90[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_87 (Conv2D)             (None, 3, 3, 384)    442368      ['activation_86[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_88 (Conv2D)             (None, 3, 3, 384)    442368      ['activation_86[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_91 (Conv2D)             (None, 3, 3, 384)    442368      ['activation_90[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_92 (Conv2D)             (None, 3, 3, 384)    442368      ['activation_90[0][0]']          \n",
      "                                                                                                  \n",
      " average_pooling2d_8 (AveragePo  (None, 3, 3, 2048)  0           ['mixed9[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_85 (Conv2D)             (None, 3, 3, 320)    655360      ['mixed9[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_87 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_87[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_88 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_88[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_91 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_91[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_92 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_92[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_93 (Conv2D)             (None, 3, 3, 192)    393216      ['average_pooling2d_8[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_85 (BatchN  (None, 3, 3, 320)   960         ['conv2d_85[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_87 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_87[0][0]'] \n",
      "                                                                                                  \n",
      " activation_88 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_88[0][0]'] \n",
      "                                                                                                  \n",
      " activation_91 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_91[0][0]'] \n",
      "                                                                                                  \n",
      " activation_92 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_92[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_93 (BatchN  (None, 3, 3, 192)   576         ['conv2d_93[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_85 (Activation)     (None, 3, 3, 320)    0           ['batch_normalization_85[0][0]'] \n",
      "                                                                                                  \n",
      " mixed9_1 (Concatenate)         (None, 3, 3, 768)    0           ['activation_87[0][0]',          \n",
      "                                                                  'activation_88[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 3, 3, 768)    0           ['activation_91[0][0]',          \n",
      "                                                                  'activation_92[0][0]']          \n",
      "                                                                                                  \n",
      " activation_93 (Activation)     (None, 3, 3, 192)    0           ['batch_normalization_93[0][0]'] \n",
      "                                                                                                  \n",
      " mixed10 (Concatenate)          (None, 3, 3, 2048)   0           ['activation_85[0][0]',          \n",
      "                                                                  'mixed9_1[0][0]',               \n",
      "                                                                  'concatenate_1[0][0]',          \n",
      "                                                                  'activation_93[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 21,802,784\n",
      "Trainable params: 0\n",
      "Non-trainable params: 21,802,784\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "path_inception = work_path + f\"tmp2/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n",
    "\n",
    "# Import the inception model  \n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "# Create an instance of the inception model from the local pre-trained weights\n",
    "local_weights_file = path_inception\n",
    "\n",
    "pre_trained_model = InceptionV3(input_shape = (150, 150, 3), \n",
    "                                include_top = False, \n",
    "                                weights = None) \n",
    "\n",
    "pre_trained_model.load_weights(local_weights_file)\n",
    "\n",
    "# Make all the layers in the pre-trained model non-trainable\n",
    "for layer in pre_trained_model.layers:\n",
    "  layer.trainable = False \n",
    "  \n",
    "# Print the model summary\n",
    "pre_trained_model.summary()\n",
    "\n",
    "# Expected Output is extremely large, but should end with:\n",
    "\n",
    "#batch_normalization_v1_281 (Bat (None, 3, 3, 192)    576         conv2d_281[0][0]                 \n",
    "#__________________________________________________________________________________________________\n",
    "#activation_273 (Activation)     (None, 3, 3, 320)    0           batch_normalization_v1_273[0][0] \n",
    "#__________________________________________________________________________________________________\n",
    "#mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_275[0][0]             \n",
    "#                                                                 activation_276[0][0]             \n",
    "#__________________________________________________________________________________________________\n",
    "#concatenate_5 (Concatenate)     (None, 3, 3, 768)    0           activation_279[0][0]             \n",
    "#                                                                 activation_280[0][0]             \n",
    "#__________________________________________________________________________________________________\n",
    "#activation_281 (Activation)     (None, 3, 3, 192)    0           batch_normalization_v1_281[0][0] \n",
    "#__________________________________________________________________________________________________\n",
    "#mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_273[0][0]             \n",
    "#                                                                 mixed9_1[0][0]                   \n",
    "#                                                                 concatenate_5[0][0]              \n",
    "#                                                                 activation_281[0][0]             \n",
    "#==================================================================================================\n",
    "#Total params: 21,802,784\n",
    "#Trainable params: 0\n",
    "#Non-trainable params: 21,802,784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CFsUlwdfs_wg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last layer output shape:  (None, 7, 7, 768)\n"
     ]
    }
   ],
   "source": [
    "last_layer = pre_trained_model.get_layer('mixed7')\n",
    "print('last layer output shape: ', last_layer.output_shape)\n",
    "last_output = last_layer.output\n",
    "\n",
    "# Expected Output:\n",
    "# ('last layer output shape: ', (None, 7, 7, 768))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-bsWZWp5oMq9"
   },
   "outputs": [],
   "source": [
    "# Define a Callback class that stops training once accuracy reaches 97.0%\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    if(logs.get('acc')>0.97):\n",
    "      print(\"\\nReached 97.0% accuracy so cancelling training!\")\n",
    "      self.model.stop_training = True\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BMXb913pbvFg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 150, 150, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 74, 74, 32)   864         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 74, 74, 32)  96          ['conv2d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 74, 74, 32)   0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 72, 72, 32)   9216        ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 72, 72, 32)  96          ['conv2d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 72, 72, 32)   0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 72, 72, 64)   18432       ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 72, 72, 64)  192         ['conv2d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 72, 72, 64)   0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 35, 35, 64)   0           ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 35, 35, 80)   5120        ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 35, 35, 80)  240         ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 35, 35, 80)   0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 33, 33, 192)  138240      ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 33, 33, 192)  576        ['conv2d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 33, 33, 192)  0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0          ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 16, 16, 64)   12288       ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 16, 16, 64)  192         ['conv2d_8[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 16, 16, 64)   0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 16, 16, 48)   9216        ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 16, 16, 96)   55296       ['activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 16, 16, 48)  144         ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 16, 16, 96)  288         ['conv2d_9[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 16, 16, 48)   0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 16, 16, 96)   0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " average_pooling2d (AveragePool  (None, 16, 16, 192)  0          ['max_pooling2d_1[0][0]']        \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 16, 16, 64)   12288       ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 16, 16, 64)   76800       ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 16, 16, 96)   82944       ['activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 16, 16, 32)   6144        ['average_pooling2d[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 16, 16, 64)  192         ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 16, 16, 64)  192         ['conv2d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 16, 16, 96)  288         ['conv2d_10[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 16, 16, 32)  96          ['conv2d_11[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 16, 16, 64)   0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 16, 16, 64)   0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 16, 16, 96)   0           ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 16, 16, 32)   0           ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " mixed0 (Concatenate)           (None, 16, 16, 256)  0           ['activation_5[0][0]',           \n",
      "                                                                  'activation_7[0][0]',           \n",
      "                                                                  'activation_10[0][0]',          \n",
      "                                                                  'activation_11[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 16, 16, 64)   16384       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 16, 16, 64)  192         ['conv2d_15[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_15 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 16, 16, 48)   12288       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 16, 16, 96)   55296       ['activation_15[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 16, 16, 48)  144         ['conv2d_13[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 16, 16, 96)  288         ['conv2d_16[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_13 (Activation)     (None, 16, 16, 48)   0           ['batch_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " activation_16 (Activation)     (None, 16, 16, 96)   0           ['batch_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_1 (AveragePo  (None, 16, 16, 256)  0          ['mixed0[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 16, 16, 64)   16384       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 16, 16, 64)   76800       ['activation_13[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 16, 16, 96)   82944       ['activation_16[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 16, 16, 64)   16384       ['average_pooling2d_1[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 16, 16, 64)  192         ['conv2d_12[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 16, 16, 64)  192         ['conv2d_14[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 16, 16, 96)  288         ['conv2d_17[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 16, 16, 64)  192         ['conv2d_18[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " activation_14 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " activation_17 (Activation)     (None, 16, 16, 96)   0           ['batch_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " activation_18 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " mixed1 (Concatenate)           (None, 16, 16, 288)  0           ['activation_12[0][0]',          \n",
      "                                                                  'activation_14[0][0]',          \n",
      "                                                                  'activation_17[0][0]',          \n",
      "                                                                  'activation_18[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)             (None, 16, 16, 64)   18432       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_22 (BatchN  (None, 16, 16, 64)  192         ['conv2d_22[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_22 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_22[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, 16, 16, 48)   13824       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)             (None, 16, 16, 96)   55296       ['activation_22[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_20 (BatchN  (None, 16, 16, 48)  144         ['conv2d_20[0][0]']              \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\junwi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\optimizers\\legacy\\rmsprop.py:143: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_23 (BatchN  (None, 16, 16, 96)  288         ['conv2d_23[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_20 (Activation)     (None, 16, 16, 48)   0           ['batch_normalization_20[0][0]'] \n",
      "                                                                                                  \n",
      " activation_23 (Activation)     (None, 16, 16, 96)   0           ['batch_normalization_23[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_2 (AveragePo  (None, 16, 16, 288)  0          ['mixed1[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 16, 16, 64)   18432       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)             (None, 16, 16, 64)   76800       ['activation_20[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)             (None, 16, 16, 96)   82944       ['activation_23[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)             (None, 16, 16, 64)   18432       ['average_pooling2d_2[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_19 (BatchN  (None, 16, 16, 64)  192         ['conv2d_19[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_21 (BatchN  (None, 16, 16, 64)  192         ['conv2d_21[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_24 (BatchN  (None, 16, 16, 96)  288         ['conv2d_24[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_25 (BatchN  (None, 16, 16, 64)  192         ['conv2d_25[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_19 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_19[0][0]'] \n",
      "                                                                                                  \n",
      " activation_21 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_21[0][0]'] \n",
      "                                                                                                  \n",
      " activation_24 (Activation)     (None, 16, 16, 96)   0           ['batch_normalization_24[0][0]'] \n",
      "                                                                                                  \n",
      " activation_25 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_25[0][0]'] \n",
      "                                                                                                  \n",
      " mixed2 (Concatenate)           (None, 16, 16, 288)  0           ['activation_19[0][0]',          \n",
      "                                                                  'activation_21[0][0]',          \n",
      "                                                                  'activation_24[0][0]',          \n",
      "                                                                  'activation_25[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)             (None, 16, 16, 64)   18432       ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_27 (BatchN  (None, 16, 16, 64)  192         ['conv2d_27[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_27 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_27[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_28 (Conv2D)             (None, 16, 16, 96)   55296       ['activation_27[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_28 (BatchN  (None, 16, 16, 96)  288         ['conv2d_28[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_28 (Activation)     (None, 16, 16, 96)   0           ['batch_normalization_28[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)             (None, 7, 7, 384)    995328      ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_29 (Conv2D)             (None, 7, 7, 96)     82944       ['activation_28[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_26 (BatchN  (None, 7, 7, 384)   1152        ['conv2d_26[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_29 (BatchN  (None, 7, 7, 96)    288         ['conv2d_29[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_26 (Activation)     (None, 7, 7, 384)    0           ['batch_normalization_26[0][0]'] \n",
      "                                                                                                  \n",
      " activation_29 (Activation)     (None, 7, 7, 96)     0           ['batch_normalization_29[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)   0           ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " mixed3 (Concatenate)           (None, 7, 7, 768)    0           ['activation_26[0][0]',          \n",
      "                                                                  'activation_29[0][0]',          \n",
      "                                                                  'max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_34 (Conv2D)             (None, 7, 7, 128)    98304       ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_34 (BatchN  (None, 7, 7, 128)   384         ['conv2d_34[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_34 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_34[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_35 (Conv2D)             (None, 7, 7, 128)    114688      ['activation_34[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_35 (BatchN  (None, 7, 7, 128)   384         ['conv2d_35[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_35 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_35[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_31 (Conv2D)             (None, 7, 7, 128)    98304       ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_36 (Conv2D)             (None, 7, 7, 128)    114688      ['activation_35[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_31 (BatchN  (None, 7, 7, 128)   384         ['conv2d_31[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_36 (BatchN  (None, 7, 7, 128)   384         ['conv2d_36[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_31 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_31[0][0]'] \n",
      "                                                                                                  \n",
      " activation_36 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_36[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_32 (Conv2D)             (None, 7, 7, 128)    114688      ['activation_31[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_37 (Conv2D)             (None, 7, 7, 128)    114688      ['activation_36[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_32 (BatchN  (None, 7, 7, 128)   384         ['conv2d_32[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_37 (BatchN  (None, 7, 7, 128)   384         ['conv2d_37[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_32 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_32[0][0]'] \n",
      "                                                                                                  \n",
      " activation_37 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_37[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_3 (AveragePo  (None, 7, 7, 768)   0           ['mixed3[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_33 (Conv2D)             (None, 7, 7, 192)    172032      ['activation_32[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_38 (Conv2D)             (None, 7, 7, 192)    172032      ['activation_37[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_39 (Conv2D)             (None, 7, 7, 192)    147456      ['average_pooling2d_3[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_30 (BatchN  (None, 7, 7, 192)   576         ['conv2d_30[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_33 (BatchN  (None, 7, 7, 192)   576         ['conv2d_33[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_38 (BatchN  (None, 7, 7, 192)   576         ['conv2d_38[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_39 (BatchN  (None, 7, 7, 192)   576         ['conv2d_39[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_30 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_30[0][0]'] \n",
      "                                                                                                  \n",
      " activation_33 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_33[0][0]'] \n",
      "                                                                                                  \n",
      " activation_38 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_38[0][0]'] \n",
      "                                                                                                  \n",
      " activation_39 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_39[0][0]'] \n",
      "                                                                                                  \n",
      " mixed4 (Concatenate)           (None, 7, 7, 768)    0           ['activation_30[0][0]',          \n",
      "                                                                  'activation_33[0][0]',          \n",
      "                                                                  'activation_38[0][0]',          \n",
      "                                                                  'activation_39[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_44 (Conv2D)             (None, 7, 7, 160)    122880      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_44 (BatchN  (None, 7, 7, 160)   480         ['conv2d_44[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_44 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_44[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_45 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_44[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_45 (BatchN  (None, 7, 7, 160)   480         ['conv2d_45[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_45 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_45[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_41 (Conv2D)             (None, 7, 7, 160)    122880      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_46 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_45[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_41 (BatchN  (None, 7, 7, 160)   480         ['conv2d_41[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_46 (BatchN  (None, 7, 7, 160)   480         ['conv2d_46[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_41 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_41[0][0]'] \n",
      "                                                                                                  \n",
      " activation_46 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_46[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_42 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_41[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_47 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_46[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_42 (BatchN  (None, 7, 7, 160)   480         ['conv2d_42[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_47 (BatchN  (None, 7, 7, 160)   480         ['conv2d_47[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_42 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_42[0][0]'] \n",
      "                                                                                                  \n",
      " activation_47 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_47[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_4 (AveragePo  (None, 7, 7, 768)   0           ['mixed4[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_40 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_43 (Conv2D)             (None, 7, 7, 192)    215040      ['activation_42[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_48 (Conv2D)             (None, 7, 7, 192)    215040      ['activation_47[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_49 (Conv2D)             (None, 7, 7, 192)    147456      ['average_pooling2d_4[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_40 (BatchN  (None, 7, 7, 192)   576         ['conv2d_40[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_43 (BatchN  (None, 7, 7, 192)   576         ['conv2d_43[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_48 (BatchN  (None, 7, 7, 192)   576         ['conv2d_48[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_49 (BatchN  (None, 7, 7, 192)   576         ['conv2d_49[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_40 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_40[0][0]'] \n",
      "                                                                                                  \n",
      " activation_43 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_43[0][0]'] \n",
      "                                                                                                  \n",
      " activation_48 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_48[0][0]'] \n",
      "                                                                                                  \n",
      " activation_49 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_49[0][0]'] \n",
      "                                                                                                  \n",
      " mixed5 (Concatenate)           (None, 7, 7, 768)    0           ['activation_40[0][0]',          \n",
      "                                                                  'activation_43[0][0]',          \n",
      "                                                                  'activation_48[0][0]',          \n",
      "                                                                  'activation_49[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_54 (Conv2D)             (None, 7, 7, 160)    122880      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_54 (BatchN  (None, 7, 7, 160)   480         ['conv2d_54[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_54 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_54[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_55 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_54[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_55 (BatchN  (None, 7, 7, 160)   480         ['conv2d_55[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_55 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_55[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_51 (Conv2D)             (None, 7, 7, 160)    122880      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_56 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_55[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_51 (BatchN  (None, 7, 7, 160)   480         ['conv2d_51[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_56 (BatchN  (None, 7, 7, 160)   480         ['conv2d_56[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_51 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_51[0][0]'] \n",
      "                                                                                                  \n",
      " activation_56 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_56[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_52 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_51[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_57 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_56[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_52 (BatchN  (None, 7, 7, 160)   480         ['conv2d_52[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_57 (BatchN  (None, 7, 7, 160)   480         ['conv2d_57[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_52 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_52[0][0]'] \n",
      "                                                                                                  \n",
      " activation_57 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_57[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_5 (AveragePo  (None, 7, 7, 768)   0           ['mixed5[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_50 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_53 (Conv2D)             (None, 7, 7, 192)    215040      ['activation_52[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_58 (Conv2D)             (None, 7, 7, 192)    215040      ['activation_57[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_59 (Conv2D)             (None, 7, 7, 192)    147456      ['average_pooling2d_5[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_50 (BatchN  (None, 7, 7, 192)   576         ['conv2d_50[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_53 (BatchN  (None, 7, 7, 192)   576         ['conv2d_53[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_58 (BatchN  (None, 7, 7, 192)   576         ['conv2d_58[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_59 (BatchN  (None, 7, 7, 192)   576         ['conv2d_59[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_50 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_50[0][0]'] \n",
      "                                                                                                  \n",
      " activation_53 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_53[0][0]'] \n",
      "                                                                                                  \n",
      " activation_58 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_58[0][0]'] \n",
      "                                                                                                  \n",
      " activation_59 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_59[0][0]'] \n",
      "                                                                                                  \n",
      " mixed6 (Concatenate)           (None, 7, 7, 768)    0           ['activation_50[0][0]',          \n",
      "                                                                  'activation_53[0][0]',          \n",
      "                                                                  'activation_58[0][0]',          \n",
      "                                                                  'activation_59[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_64 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_64 (BatchN  (None, 7, 7, 192)   576         ['conv2d_64[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_64 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_64[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_65 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_64[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_65 (BatchN  (None, 7, 7, 192)   576         ['conv2d_65[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_65 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_65[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_61 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_66 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_65[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_61 (BatchN  (None, 7, 7, 192)   576         ['conv2d_61[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_66 (BatchN  (None, 7, 7, 192)   576         ['conv2d_66[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_61 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_61[0][0]'] \n",
      "                                                                                                  \n",
      " activation_66 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_66[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_62 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_61[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_67 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_66[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_62 (BatchN  (None, 7, 7, 192)   576         ['conv2d_62[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_67 (BatchN  (None, 7, 7, 192)   576         ['conv2d_67[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_62 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_62[0][0]'] \n",
      "                                                                                                  \n",
      " activation_67 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_67[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_6 (AveragePo  (None, 7, 7, 768)   0           ['mixed6[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_60 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_63 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_62[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_68 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_67[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_69 (Conv2D)             (None, 7, 7, 192)    147456      ['average_pooling2d_6[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_60 (BatchN  (None, 7, 7, 192)   576         ['conv2d_60[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_63 (BatchN  (None, 7, 7, 192)   576         ['conv2d_63[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_68 (BatchN  (None, 7, 7, 192)   576         ['conv2d_68[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_69 (BatchN  (None, 7, 7, 192)   576         ['conv2d_69[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_60 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_60[0][0]'] \n",
      "                                                                                                  \n",
      " activation_63 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_63[0][0]'] \n",
      "                                                                                                  \n",
      " activation_68 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_68[0][0]'] \n",
      "                                                                                                  \n",
      " activation_69 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_69[0][0]'] \n",
      "                                                                                                  \n",
      " mixed7 (Concatenate)           (None, 7, 7, 768)    0           ['activation_60[0][0]',          \n",
      "                                                                  'activation_63[0][0]',          \n",
      "                                                                  'activation_68[0][0]',          \n",
      "                                                                  'activation_69[0][0]']          \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 37632)        0           ['mixed7[0][0]']                 \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 1024)         38536192    ['flatten_1[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 1024)         0           ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 1)            1025        ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 47,512,481\n",
      "Trainable params: 38,537,217\n",
      "Non-trainable params: 8,975,264\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import RMSprop\n",
    "\n",
    "# Flatten the output layer to 1 dimension\n",
    "x = layers.Flatten()(last_output)\n",
    "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
    "x = layers.Dense(1024, activation='relu')(x)\n",
    "# Add a dropout rate of 0.2\n",
    "x = layers.Dropout(0.2)(x)                  \n",
    "# Add a final sigmoid layer for classification\n",
    "x = layers.Dense  (1, activation='sigmoid')(x)           \n",
    "\n",
    "model = Model( pre_trained_model.input, x) \n",
    "\n",
    "model.compile(optimizer = RMSprop(lr=0.0001), \n",
    "              loss = 'binary_crossentropy', \n",
    "              metrics = ['acc'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Expected output will be large. Last few lines should be:\n",
    "\n",
    "# mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_248[0][0]             \n",
    "#                                                                  activation_251[0][0]             \n",
    "#                                                                  activation_256[0][0]             \n",
    "#                                                                  activation_257[0][0]             \n",
    "# __________________________________________________________________________________________________\n",
    "# flatten_4 (Flatten)             (None, 37632)        0           mixed7[0][0]                     \n",
    "# __________________________________________________________________________________________________\n",
    "# dense_8 (Dense)                 (None, 1024)         38536192    flatten_4[0][0]                  \n",
    "# __________________________________________________________________________________________________\n",
    "# dropout_4 (Dropout)             (None, 1024)         0           dense_8[0][0]                    \n",
    "# __________________________________________________________________________________________________\n",
    "# dense_9 (Dense)                 (None, 1)            1025        dropout_4[0][0]                  \n",
    "# ==================================================================================================\n",
    "# Total params: 47,512,481\n",
    "# Trainable params: 38,537,217\n",
    "# Non-trainable params: 8,975,264\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HrnL_IQ8knWA"
   },
   "outputs": [],
   "source": [
    "# Get the Horse or Human dataset\n",
    "path_horse_or_human = f\"C:/Users/junwi/Downloads/horse-or-human.zip\"\n",
    "# Get the Horse or Human Validation dataset\n",
    "path_validation_horse_or_human = f\"C:/Users/junwi/Downloads/validation-horse-or-human.zip\"\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import os\n",
    "import zipfile\n",
    "import shutil\n",
    "\n",
    "shutil.rmtree(work_path +'tmp')\n",
    "local_zip = path_horse_or_human\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall(work_path + 'tmp/training')\n",
    "zip_ref.close()\n",
    "\n",
    "local_zip = path_validation_horse_or_human\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall(work_path + 'tmp/validation')\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y9okX7_ovskI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "527\n",
      "128\n",
      "128\n"
     ]
    }
   ],
   "source": [
    "# Define our example directories and files\n",
    "train_dir = work_path +'tmp/training'\n",
    "validation_dir = work_path +'tmp/validation'\n",
    "\n",
    "train_horses_dir = train_dir + '/horses'\n",
    "train_humans_dir = train_dir +  '/humans'\n",
    "validation_horses_dir = validation_dir + '/horses'\n",
    "validation_humans_dir = validation_dir + '/humans'\n",
    "\n",
    "train_horses_fnames = os.listdir(train_horses_dir) \n",
    "train_humans_fnames = os.listdir(train_humans_dir) \n",
    "validation_horses_fnames = os.listdir(validation_horses_dir) \n",
    "validation_humans_fnames = os.listdir(validation_humans_dir) \n",
    "\n",
    "print(len(train_horses_fnames))\n",
    "print(len(train_humans_fnames)) \n",
    "print(len(validation_horses_fnames))\n",
    "print(len(validation_humans_fnames))\n",
    "\n",
    "# Expected Output:\n",
    "# 500\n",
    "# 527\n",
    "# 128\n",
    "# 128"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    rescale: This rescales the pixel values of the images so that they are between 0 and 1. This is a common preprocessing step for image data, as it can make it easier for the model to learn the underlying patterns in the data.\n",
    "\n",
    "    rotation_range: This randomly rotates the images by a certain number of degrees. In this case, the range is set to 40 degrees, which means that the images can be rotated by up to 40 degrees in either direction.\n",
    "\n",
    "    width_shift_range and height_shift_range: These randomly shift the images horizontally and vertically by a certain percentage of their width and height. In this case, the range is set to 0.2, which means that the images can be shifted by up to 20% of their width or height.\n",
    "\n",
    "    shear_range: This randomly applies a shear transformation to the images, which distorts them along one axis while keeping the other axis fixed. In this case, the range is set to 0.2, which means that the images can be sheared by up to 20% of their width or height.\n",
    "\n",
    "    zoom_range: This randomly applies a zoom transformation to the images, which either zooms in or out on the image. In this case, the range is set to 0.2, which means that the images can be zoomed in or out by up to 20%.\n",
    "\n",
    "    horizontal_flip: This randomly flips the images horizontally. This can help introduce more variety in the training data, as it effectively doubles the number of images by providing a mirror image for each original image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O4s8HckqGlnb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1027 images belonging to 2 classes.\n",
      "Found 256 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Add our data-augmentation parameters to ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(ImageDataGenerator(rescale = 1./255.,\n",
    "                                   rotation_range = 40,\n",
    "                                   width_shift_range = 0.2,\n",
    "                                   height_shift_range = 0.2,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True))\n",
    "\n",
    "train_datagen2 = ImageDataGenerator( rescale = 1.0/255., rotation_range = 40, width_shift_range = 0.2,\n",
    "                                    height_shift_range = 0.2, shear_range = 0.2,\n",
    "                                    zoom_range = 0.2, horizontal_flip = True)\n",
    "\n",
    "# Flow training images in batches of 20 using train_datagen generator\n",
    "train_generator = train_datagen2.flow_from_directory(train_dir,\n",
    "                                                    batch_size = 20,\n",
    "                                                    class_mode = 'binary', \n",
    "                                                    target_size = (150, 150))\n",
    "\n",
    "# Note that the validation data should not be augmented!\n",
    "#test_datagen = ImageDataGenerator( rescale = 1.0/255.  )\n",
    "validation_datagen = ImageDataGenerator( rescale = 1.0/255.  )\n",
    "\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(validation_dir,\n",
    "                                                              target_size=(150, 150),\n",
    "                                                              batch_size=20,\n",
    "                                                              class_mode='binary')\n",
    "\n",
    "\n",
    "# Flow validation images in batches of 20 using test_datagen generator\n",
    "#validation_generator =  test_datagen.flow_from_directory(  validation_dir, batch_size  = 20,class_mode  = 'binary',target_size = (150, 150))\n",
    "\n",
    "# Expected Output:\n",
    "# Found 1027 images belonging to 2 classes.\n",
    "# Found 256 images belonging to 2 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model( pre_trained_model.input, x) \n",
    "\n",
    "model.compile(optimizer = RMSprop(lr=0.0001), \n",
    "              loss = 'binary_crossentropy', \n",
    "              metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Blhq2MAUeyGA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\n",
      "Reached 97.0% accuracy so cancelling training!\n",
      "50/50 - 49s - loss: 0.0204 - acc: 0.9939 - val_loss: 1.3198e-04 - val_acc: 1.0000 - 49s/epoch - 979ms/step\n"
     ]
    }
   ],
   "source": [
    "# Run this and see how many epochs it should take before the callback\n",
    "# fires, and stops training at 97% accuracy\n",
    "\n",
    "callbacks = myCallback()\n",
    "history = model.fit(\n",
    "            train_generator,\n",
    "            validation_data = validation_generator,\n",
    "            steps_per_epoch = 50,\n",
    "            epochs = 2,\n",
    "            validation_steps = 10,\n",
    "            verbose = 2,\n",
    "            callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C2Fp6Se9rKuL"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend(loc=0)\n",
    "plt.figure()\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# detecting if a picture is a horse ot human\n",
    "\n",
    "recall that -  if we have two folders named \"horses\" and \"humans\", the flow_from_directory function will assign binary label 0 to the \"horses\" category and binary label 1 to the \"humans\" category. This is because \"horses\" comes first alphabetically, so it gets assigned the label 0, and \"humans\" comes second, so it gets assigned the label 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "The predicted class is: other_class\n",
      "The prediction is: [4.0384834e-17]\n"
     ]
    }
   ],
   "source": [
    "# from keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "# image_path = work_path + f\"tmp/validation/humans/valhuman02-01.png\"\n",
    "image_path =  work_path + f\"tmp/training/horses/horse01-8.png\"\n",
    "image = keras.preprocessing.image.load_img(image_path, target_size=(150, 150))\n",
    "import numpy as np\n",
    "\n",
    "image_array = keras.preprocessing.image.img_to_array(image)\n",
    "image_array = np.expand_dims(image_array, axis=0)\n",
    "image_array /= 255.0\n",
    "\n",
    "prediction = model.predict(image_array)\n",
    "\n",
    "predicted_class = \"humans\" if prediction[0] > 0.5 else \"other_class\"\n",
    "print(f\"The predicted class is: {predicted_class}\")\n",
    "print(f\"The prediction is: {prediction[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 161ms/step\n",
      "human01-00.png: [1.]\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "human01-01.png: [1.]\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "human01-02.png: [1.]\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "human01-03.png: [1.]\n",
      "1/1 [==============================] - 0s 148ms/step\n",
      "human01-04.png: [1.]\n",
      "1/1 [==============================] - 0s 174ms/step\n",
      "human01-05.png: [1.]\n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "human01-06.png: [1.]\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "human01-07.png: [1.]\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "human01-08.png: [1.]\n",
      "1/1 [==============================] - 0s 160ms/step\n",
      "human01-09.png: [1.]\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "human01-10.png: [1.]\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "human01-11.png: [1.]\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "human01-12.png: [1.]\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "human01-13.png: [1.]\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "human01-14.png: [1.]\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "human01-15.png: [1.]\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "human01-16.png: [1.]\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "human01-17.png: [1.]\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "human01-18.png: [1.]\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "human01-19.png: [1.]\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "human01-20.png: [1.]\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "human01-21.png: [1.]\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "human01-22.png: [1.]\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "human01-23.png: [1.]\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "human01-24.png: [1.]\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "human01-25.png: [1.]\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "human01-26.png: [1.]\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "human01-27.png: [1.]\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "human01-28.png: [1.]\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "human01-29.png: [1.]\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "human01-30.png: [1.]\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "human02-00.png: [1.]\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "human02-01.png: [1.]\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "human02-02.png: [1.]\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "human02-03.png: [1.]\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "human02-04.png: [1.]\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "human02-05.png: [1.]\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "human02-06.png: [1.]\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "human02-07.png: [1.]\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "human02-08.png: [1.]\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "human02-09.png: [1.]\n",
      "1/1 [==============================] - 0s 155ms/step\n",
      "human02-10.png: [1.]\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "human02-11.png: [1.]\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "human02-12.png: [1.]\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "human02-13.png: [1.]\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "human02-14.png: [1.]\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "human02-15.png: [1.]\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "human02-16.png: [1.]\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "human02-17.png: [1.]\n",
      "1/1 [==============================] - 0s 160ms/step\n",
      "human02-18.png: [1.]\n",
      "1/1 [==============================] - 0s 173ms/step\n",
      "human02-19.png: [1.]\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "human02-20.png: [1.]\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "human02-21.png: [1.]\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "human02-22.png: [1.]\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "human02-23.png: [1.]\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "human02-24.png: [1.]\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "human02-25.png: [1.]\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "human02-26.png: [1.]\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "human02-27.png: [1.]\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "human02-28.png: [1.]\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "human02-29.png: [1.]\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "human02-30.png: [1.]\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "human03-00.png: [1.]\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "human03-01.png: [1.]\n",
      "1/1 [==============================] - 0s 155ms/step\n",
      "human03-02.png: [1.]\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "human03-03.png: [1.]\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "human03-04.png: [1.]\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "human03-05.png: [1.]\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "human03-06.png: [1.]\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "human03-07.png: [1.]\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "human03-08.png: [1.]\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "human03-09.png: [1.]\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "human03-10.png: [1.]\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "human03-11.png: [1.]\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "human03-12.png: [1.]\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "human03-13.png: [1.]\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "human03-14.png: [1.]\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "human03-15.png: [1.]\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "human03-16.png: [1.]\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "human03-17.png: [1.]\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "human03-18.png: [1.]\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "human03-19.png: [1.]\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "human03-20.png: [1.]\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "human03-21.png: [1.]\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "human03-22.png: [1.]\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "human03-23.png: [1.]\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "human03-24.png: [1.]\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "human03-25.png: [1.]\n",
      "1/1 [==============================] - 0s 148ms/step\n",
      "human03-26.png: [1.]\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "human03-27.png: [1.]\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "human03-28.png: [1.]\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "human03-29.png: [1.]\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "human03-30.png: [1.]\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "human04-00.png: [1.]\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "human04-01.png: [1.]\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "human04-02.png: [1.]\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "human04-03.png: [1.]\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "human04-04.png: [1.]\n",
      "1/1 [==============================] - 0s 153ms/step\n",
      "human04-05.png: [1.]\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "human04-06.png: [1.]\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "human04-07.png: [1.]\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "human04-08.png: [1.]\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "human04-09.png: [1.]\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "human04-10.png: [1.]\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "human04-11.png: [1.]\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "human04-12.png: [1.]\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "human04-13.png: [1.]\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "human04-14.png: [1.]\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "human04-15.png: [1.]\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "human04-16.png: [1.]\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "human04-17.png: [1.]\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "human04-18.png: [1.]\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "human04-19.png: [1.]\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "human04-20.png: [1.]\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "human04-21.png: [1.]\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "human04-22.png: [1.]\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "human04-23.png: [1.]\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "human04-24.png: [1.]\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "human04-25.png: [1.]\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "human04-26.png: [1.]\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "human04-27.png: [1.]\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "human04-28.png: [1.]\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "human04-29.png: [1.]\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "human04-30.png: [1.]\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "human05-00.png: [1.]\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "human05-01.png: [1.]\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "human05-02.png: [1.]\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "human05-03.png: [1.]\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "human05-04.png: [1.]\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "human05-05.png: [1.]\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "human05-06.png: [1.]\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "human05-07.png: [1.]\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "human05-08.png: [1.]\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "human05-09.png: [1.]\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "human05-10.png: [1.]\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "human05-11.png: [1.]\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "human05-12.png: [1.]\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "human05-13.png: [1.]\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "human05-14.png: [1.]\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "human05-15.png: [1.]\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "human05-16.png: [1.]\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "human05-17.png: [1.]\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "human05-18.png: [1.]\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "human05-19.png: [1.]\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "human05-20.png: [1.]\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "human05-21.png: [1.]\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "human05-22.png: [1.]\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "human05-23.png: [1.]\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "human05-24.png: [1.]\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "human05-25.png: [1.]\n",
      "1/1 [==============================] - 0s 160ms/step\n",
      "human05-26.png: [1.]\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "human05-27.png: [1.]\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "human05-28.png: [1.]\n",
      "1/1 [==============================] - 0s 153ms/step\n",
      "human05-29.png: [1.]\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "human05-30.png: [1.]\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "human06-00.png: [1.]\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "human06-01.png: [1.]\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "human06-02.png: [1.]\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "human06-03.png: [1.]\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "human06-04.png: [1.]\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "human06-05.png: [1.]\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "human06-06.png: [1.]\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "human06-07.png: [1.]\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "human06-08.png: [1.]\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "human06-09.png: [1.]\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "human06-10.png: [1.]\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "human06-11.png: [1.]\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "human06-12.png: [1.]\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "human06-13.png: [1.]\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "human06-14.png: [1.]\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "human06-15.png: [1.]\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "human06-16.png: [1.]\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "human06-17.png: [1.]\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "human06-18.png: [1.]\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "human06-19.png: [1.]\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "human06-20.png: [1.]\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "human06-21.png: [1.]\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "human06-22.png: [1.]\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "human06-23.png: [1.]\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "human06-24.png: [1.]\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "human06-25.png: [1.]\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "human06-26.png: [1.]\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "human06-27.png: [1.]\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "human06-28.png: [1.]\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "human06-29.png: [1.]\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "human06-30.png: [1.]\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "human07-00.png: [1.]\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "human07-01.png: [1.]\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "human07-02.png: [1.]\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "human07-03.png: [1.]\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "human07-04.png: [1.]\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "human07-05.png: [1.]\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "human07-06.png: [1.]\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "human07-07.png: [1.]\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "human07-08.png: [1.]\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "human07-09.png: [1.]\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "human07-10.png: [1.]\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "human07-11.png: [1.]\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "human07-12.png: [1.]\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "human07-13.png: [1.]\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "human07-14.png: [1.]\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "human07-15.png: [1.]\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "human07-16.png: [1.]\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "human07-17.png: [1.]\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "human07-18.png: [1.]\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "human07-19.png: [1.]\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "human07-20.png: [1.]\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "human07-21.png: [1.]\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "human07-22.png: [1.]\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "human07-23.png: [1.]\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "human07-24.png: [1.]\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "human07-25.png: [1.]\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "human07-26.png: [1.]\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "human07-27.png: [1.]\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "human07-28.png: [1.]\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "human07-29.png: [1.]\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "human07-30.png: [1.]\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "human08-00.png: [1.]\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "human08-01.png: [1.]\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "human08-02.png: [1.]\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "human08-03.png: [1.]\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "human08-04.png: [1.]\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "human08-05.png: [1.]\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "human08-06.png: [1.]\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "human08-07.png: [1.]\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "human08-08.png: [1.]\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "human08-09.png: [1.]\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "human08-10.png: [1.]\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "human08-11.png: [1.]\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "human08-12.png: [1.]\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "human08-13.png: [1.]\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "human08-14.png: [1.]\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "human08-15.png: [1.]\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "human08-16.png: [1.]\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "human08-17.png: [1.]\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "human08-18.png: [1.]\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "human08-19.png: [1.]\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "human08-20.png: [0.99999994]\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "human08-21.png: [1.]\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "human08-22.png: [1.]\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "human08-23.png: [1.]\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "human08-24.png: [1.]\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "human08-25.png: [1.]\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "human08-26.png: [1.]\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "human08-27.png: [1.]\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "human08-28.png: [1.]\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "human08-29.png: [1.]\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "human08-30.png: [1.]\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "human09-00.png: [1.]\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "human09-01.png: [1.]\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "human09-02.png: [1.]\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "human09-03.png: [1.]\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "human09-04.png: [1.]\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "human09-05.png: [1.]\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "human09-06.png: [1.]\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "human09-07.png: [1.]\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "human09-08.png: [1.]\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "human09-09.png: [1.]\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "human09-10.png: [1.]\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "human09-11.png: [1.]\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "human09-12.png: [1.]\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "human09-13.png: [1.]\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "human09-14.png: [1.]\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "human09-15.png: [1.]\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "human09-16.png: [1.]\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "human09-17.png: [1.]\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "human09-18.png: [1.]\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "human09-19.png: [1.]\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "human09-20.png: [1.]\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "human09-21.png: [1.]\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "human09-22.png: [1.]\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "human09-23.png: [1.]\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "human09-24.png: [1.]\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "human09-25.png: [1.]\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "human09-26.png: [1.]\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "human09-27.png: [1.]\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "human09-28.png: [1.]\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "human09-29.png: [1.]\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "human09-30.png: [1.]\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "human10-00.png: [1.]\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "human10-01.png: [1.]\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "human10-02.png: [1.]\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "human10-03.png: [1.]\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "human10-04.png: [1.]\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "human10-05.png: [1.]\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "human10-06.png: [1.]\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "human10-07.png: [1.]\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "human10-08.png: [1.]\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "human10-09.png: [1.]\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "human10-10.png: [1.]\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "human10-11.png: [1.]\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "human10-12.png: [1.]\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "human10-13.png: [1.]\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "human10-14.png: [1.]\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "human10-15.png: [1.]\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "human10-16.png: [1.]\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "human10-17.png: [1.]\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "human10-18.png: [1.]\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "human10-19.png: [1.]\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "human10-20.png: [1.]\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "human10-21.png: [1.]\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "human10-22.png: [1.]\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "human10-23.png: [1.]\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "human10-24.png: [1.]\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "human10-25.png: [1.]\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "human10-26.png: [1.]\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "human10-27.png: [1.]\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "human10-28.png: [1.]\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "human10-29.png: [1.]\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "human10-30.png: [1.]\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "human11-00.png: [1.]\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "human11-01.png: [1.]\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "human11-02.png: [1.]\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "human11-03.png: [1.]\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "human11-04.png: [1.]\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "human11-05.png: [1.]\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "human11-06.png: [1.]\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "human11-07.png: [1.]\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "human11-08.png: [1.]\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "human11-09.png: [1.]\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "human11-10.png: [1.]\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "human11-11.png: [1.]\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "human11-12.png: [1.]\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "human11-13.png: [1.]\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "human11-14.png: [1.]\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "human11-15.png: [1.]\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "human11-16.png: [1.]\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "human11-17.png: [1.]\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "human11-18.png: [1.]\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "human11-19.png: [1.]\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "human11-20.png: [1.]\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "human11-21.png: [1.]\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "human11-22.png: [1.]\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "human11-23.png: [1.]\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "human11-24.png: [1.]\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "human11-25.png: [1.]\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "human11-26.png: [1.]\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "human11-27.png: [1.]\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "human11-28.png: [1.]\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "human11-29.png: [1.]\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "human11-30.png: [1.]\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "human12-00.png: [1.]\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "human12-01.png: [1.]\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "human12-02.png: [1.]\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "human12-03.png: [1.]\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "human12-04.png: [1.]\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "human12-05.png: [1.]\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "human12-06.png: [1.]\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "human12-07.png: [1.]\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "human12-08.png: [1.]\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "human12-09.png: [1.]\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "human12-10.png: [1.]\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "human12-11.png: [1.]\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "human12-12.png: [1.]\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "human12-13.png: [1.]\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "human12-14.png: [1.]\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "human12-15.png: [1.]\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "human12-16.png: [1.]\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "human12-17.png: [1.]\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "human12-18.png: [1.]\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "human12-19.png: [1.]\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "human12-20.png: [1.]\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "human12-21.png: [1.]\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "human12-22.png: [1.]\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "human12-23.png: [1.]\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "human12-24.png: [1.]\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "human12-25.png: [1.]\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "human12-26.png: [1.]\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "human12-27.png: [1.]\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "human12-28.png: [1.]\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "human12-29.png: [0.99999994]\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "human12-30.png: [1.]\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "human13-00.png: [1.]\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "human13-01.png: [1.]\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "human13-02.png: [1.]\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "human13-03.png: [1.]\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "human13-04.png: [1.]\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "human13-05.png: [1.]\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "human13-06.png: [1.]\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "human13-07.png: [1.]\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "human13-08.png: [1.]\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "human13-09.png: [1.]\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "human13-10.png: [1.]\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "human13-11.png: [1.]\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "human13-12.png: [1.]\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "human13-13.png: [1.]\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "human13-14.png: [1.]\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "human13-15.png: [1.]\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "human13-16.png: [1.]\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "human13-17.png: [1.]\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "human13-18.png: [1.]\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "human13-19.png: [1.]\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "human13-20.png: [1.]\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "human13-21.png: [1.]\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "human13-22.png: [1.]\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "human13-23.png: [1.]\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "human13-24.png: [1.]\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "human13-25.png: [1.]\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "human13-26.png: [1.]\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "human13-27.png: [1.]\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "human13-28.png: [1.]\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "human13-29.png: [1.]\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "human13-30.png: [1.]\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "human14-00.png: [1.]\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "human14-01.png: [1.]\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "human14-02.png: [1.]\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "human14-03.png: [1.]\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "human14-04.png: [1.]\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "human14-05.png: [1.]\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "human14-06.png: [1.]\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "human14-07.png: [1.]\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "human14-08.png: [1.]\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "human14-09.png: [1.]\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "human14-10.png: [1.]\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "human14-11.png: [1.]\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "human14-12.png: [1.]\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "human14-13.png: [1.]\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "human14-14.png: [0.99999994]\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "human14-15.png: [1.]\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "human14-16.png: [1.]\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "human14-17.png: [1.]\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "human14-18.png: [1.]\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "human14-19.png: [1.]\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "human14-20.png: [1.]\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "human14-21.png: [1.]\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "human14-22.png: [1.]\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "human14-23.png: [1.]\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "human14-24.png: [1.]\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "human14-25.png: [1.]\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "human14-26.png: [1.]\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "human14-27.png: [1.]\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "human14-28.png: [1.]\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "human14-29.png: [1.]\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "human14-30.png: [1.]\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "human15-00.png: [1.]\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "human15-01.png: [1.]\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "human15-02.png: [1.]\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "human15-03.png: [1.]\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "human15-04.png: [1.]\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "human15-05.png: [1.]\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "human15-06.png: [1.]\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "human15-07.png: [1.]\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "human15-08.png: [1.]\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "human15-09.png: [1.]\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "human15-10.png: [1.]\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "human15-11.png: [1.]\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "human15-12.png: [1.]\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "human15-13.png: [1.]\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "human15-14.png: [1.]\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "human15-15.png: [1.]\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "human15-16.png: [1.]\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "human15-17.png: [1.]\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "human15-18.png: [1.]\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "human15-19.png: [1.]\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "human15-20.png: [1.]\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "human15-21.png: [1.]\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "human15-22.png: [1.]\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "human15-23.png: [1.]\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "human15-24.png: [1.]\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "human15-25.png: [1.]\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "human15-26.png: [1.]\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "human15-27.png: [1.]\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "human15-28.png: [1.]\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "human15-29.png: [1.]\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "human15-30.png: [1.]\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "human16-00.png: [1.]\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "human16-01.png: [1.]\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "human16-02.png: [1.]\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "human16-03.png: [1.]\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "human16-04.png: [1.]\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "human16-05.png: [1.]\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "human16-06.png: [1.]\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "human16-07.png: [1.]\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "human16-08.png: [1.]\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "human16-09.png: [1.]\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "human16-10.png: [1.]\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "human16-11.png: [1.]\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "human16-12.png: [1.]\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "human16-13.png: [1.]\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "human16-14.png: [1.]\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "human16-15.png: [1.]\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "human16-16.png: [1.]\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "human16-17.png: [1.]\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "human16-18.png: [1.]\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "human16-19.png: [1.]\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "human16-20.png: [1.]\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "human16-21.png: [1.]\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "human16-22.png: [1.]\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "human16-23.png: [1.]\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "human16-24.png: [1.]\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "human16-25.png: [1.]\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "human16-26.png: [1.]\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "human16-27.png: [1.]\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "human16-28.png: [1.]\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "human16-29.png: [1.]\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "human16-30.png: [1.]\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "human17-00.png: [1.]\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "human17-01.png: [1.]\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "human17-02.png: [1.]\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "human17-03.png: [1.]\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "human17-04.png: [1.]\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "human17-05.png: [1.]\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "human17-06.png: [1.]\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "human17-07.png: [1.]\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "human17-08.png: [1.]\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "human17-09.png: [1.]\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "human17-10.png: [1.]\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "human17-11.png: [1.]\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "human17-12.png: [1.]\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "human17-13.png: [1.]\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "human17-14.png: [1.]\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "human17-15.png: [1.]\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "human17-16.png: [1.]\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "human17-17.png: [1.]\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "human17-18.png: [1.]\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "human17-19.png: [1.]\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "human17-20.png: [1.]\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "human17-21.png: [1.]\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "human17-22.png: [1.]\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "human17-23.png: [1.]\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "human17-24.png: [1.]\n",
      "1/1 [==============================] - 0s 170ms/step\n",
      "human17-25.png: [1.]\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "human17-26.png: [1.]\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "human17-27.png: [1.]\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "human17-28.png: [1.]\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "human17-29.png: [1.]\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "human17-30.png: [1.]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Load the saved model\n",
    "# model = keras.models.load_model(\"my_model.h5\")\n",
    "\n",
    "# Define the path to the folder containing the images to predict\n",
    "folder_path = work_path + f\"tmp/training/humans\"\n",
    "\n",
    "# Create a list of all the image file names in the folder\n",
    "file_names = os.listdir(folder_path)\n",
    "\n",
    "# Loop through each image file and make a prediction\n",
    "for file_name in file_names:\n",
    "    # Load the image and preprocess it\n",
    "    image_path = os.path.join(folder_path, file_name)\n",
    "    image = keras.preprocessing.image.load_img(image_path, target_size=(150, 150))\n",
    "    image_array = keras.preprocessing.image.img_to_array(image)\n",
    "    image_array = np.expand_dims(image_array, axis=0)\n",
    "    image_array /= 255.0\n",
    "    \n",
    "    # Make the prediction\n",
    "    prediction = model.predict(image_array)\n",
    "    \n",
    "    # Print the file name and prediction\n",
    "    print(f\"{file_name}: {prediction[0]}\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Exercise 7 - Question.ipynb",
   "provenance": []
  },
  "coursera": {
   "course_slug": "convolutional-neural-networks-tensorflow",
   "graded_item_id": "csg1x",
   "launcher_item_id": "GpKYz"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
